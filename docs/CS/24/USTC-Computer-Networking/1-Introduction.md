# Lec 1.0: 介绍

## 计网核心：分层

计算机网络的核心就是**分层**。

具体地，对于每一层，都

- 利用下一层提供的接口
- 实现本层的功能和接口
- 从而为上一层提供服务

注：物理层的下一层可以视作**宇宙的物理规律**，应用层的上一层可以认为是**人**。

## 各层简介

<img src="https://cdn.jsdelivr.net/gh/mtdickens/mtd-images/img/202402232042105.png" alt="The TCP/IP Five-layer Network Model | Parth Shandilya" style="zoom: 33%;" />

如图，这是 5-layer model。

其中

- 应用层提供**应用到应用**的服务。比如允许 Chrome, Firefox 与 Apache, Nginx 之间进行通信。
- 传输层提供**进程到进程（端口到端口）**的服务。
  - 通过特殊的协议，可以将不可靠的服务变成可靠的
  - 通过区分端口，允许不同进程运行在同一个主机上
    - 从而一个主机可以提供多种服务，并通过端口号区分
- 网络层提供**端到端（主机到主机）**的服务。
  - 这个服务是**尽力而为**的，i.e. 不可靠的

- 数据链路层提供**点到点**的服务。
  - i.e. 主机到主机的过程中，会有很多跳。每一跳就是由两个网卡之间交互完成。网卡之间的交互，用的就是数据链路层协议。
- 物理层将数字信号转换成光/电信号，借助各种媒介（光缆/同轴电缆/……）进行传输

## 各个层的介绍和协议

### 网络层

传统上，通过以下两个协议来进行工作：

- Internet Protocol
  - 收到一个 IP 分组
  - 根据路由表，找到相应的表项
  - 通过对应的物理端口进行转发
    - 如果查不到，就按照默认的路径转走
- 路由协议
  - 路由器之间交换路由信息
  - 然后通过路由算法来算出路由表

---

现代路由器，使用了 SDN 的方式。如[下文](https://www.cloudflare.com/zh-cn/learning/network-layer/what-is-sdn/)所述：

从技术上讲，SDN 是通过将控制平面与数据平面分离而实现的。“平面”是一个网络术语，指的是联网过程所处位置的一种抽象概念。

- **控制平面是引导网络流量的联网过程**
- 而**数据平面是穿越网络的实际数据**。

控制平面通过建立网络路由并传达应使用哪些协议来完成这个过程。

打个比方，控制平面是在城市道路交叉口工作的交通信号灯的集合。数据平面则更像是在道路上行驶、在路口停下并遵守交通信号灯的汽车。

在仅使用物理硬件的网络设置中，必须逐一配置各个路由器或交换机。控制平面（即，路由协议，计算出路由表）与数据平面和底层网络硬件紧密相连。

使用 SDN 时，控制平面（即，网络操作系统，计算出流表）与数据平面和实际硬件是分离的，从而能够从中央位置配置控制平面。

优势：

1. 可编程
2. 功能强大。如
   - 负载均衡
   - ……
3. All in one，比如说防火墙等功能，均可以采用 SDN 实现

### 数据链路层

在相邻两点之间，传输以**帧**为单位的数据。

# Lec 1.1：什么是 Internet

## 什么是 Internet

### 网络

网络就是无向图。与长度和形状均无关。就是一个拓扑。

### 计算机网络

计算机网络就是联网的计算机所构成的系统。

具体地，这里的“计算机”可以分为

- **主机节点**，比如说（联网的）手机、冰箱、空调、Web 服务器、……
  - 是数据的源或者目标
  - 往往由硬件、支持网络协议栈的 OS 以及之上运行的网络应用程序构成
  - 别称为 host, end-system 等等
- **数据交换节点，**比如说负载均衡设备（传输层、应用层）、路由器（网络层）、交换机（链路层）等等
  - 是数据的中转节点
  - 中转节点的配合，实现了数据从源节点到目标节点的传输

---

另外，除了节点（计算机）以外，还有**边**，也就是**通信链路**。分为

- 接入网链路：主机连接到互联网的链路
- 主干链路：路由器间的链路

另外，链路的容量被称为**带宽**。

### 互联网

由以 TCP/IP 协议为主的一簇协议支撑起的、使用的人数最多的网络，就是互联网。

特征：

- “网络的网络”：由各个大大小小的网络（e.g. ISP）相互连接，从而形成的 Internet of Internet
- RFC：用于提交你认为互联网应该有的改进等
- IETF：非营利组织。筛选靠谱的 RFC，进行编号，并放在网站上。所有 IP 及 IP 以上的协议，都在 RFC 上。

## 什么是协议

定义：对等层的实体在通讯过程中，应该遵守的**规则集合**。

对等层的实体，比如

- 两个网络软件
- 两个 TCP 模块（通常在操作系统内核中）
- 两个 hosts 
- 两张网卡
- ……

协议包含语法（每个字段代表的含义）、语义（字段中的具体二进制码代表的实际意思）、时序、动作。

---

总结：协议定义了在两个或多个通信实体之间交换的报文格式和次序，以及在报文传输和/或接收或其他事件方面所采取的动作。

## 什么是 Internet：从服务角度

从应用的角度来看，互联网是**分布式的应用**，同时扮演基础设施的角色，为（分布式）应用提供**通讯服务**。

- 实际上，主机应用层以下的所有层+互联网（我们目前可以认为只包含网络层及以下）一起为应用提供了服务。
  - 提供服务的形式，就是 (socket) API
    - 分为面向连接的服务（e.g. TCP/IP 协议）和无连接的服务（e.g. UDP 协议）
- 互联网唯一存在的目的，就是为分布式应用提供服务。
  - i.e. 如果世界上没有分布式应用，也就不需要互联网了。

# Lec 1.2：网络边缘

## 网络的结构

从结构上考虑网络，网络可以分为三个部分：

- 网络边缘（edge）：**主机**、应用程序（网络存在的理由）
- 网络核心（core）：**互联着的路由器**、“网络的网络”
  - “复用”线路，把所有的边缘节点接到一起
- 接入网、物理媒体（access）：**有线/无线通信链路**
  - 将网络边缘连接到网络核心

如下图所示：

<img src="https://cdn.jsdelivr.net/gh/mtdickens/mtd-images/img/202402241621035.png" alt="image-20240224162106227" style="zoom:50%;" />

## 网络边缘

- 端系统（主机）
  - 运行应用程序
  - 比如 Web、Email
- 两种运行模式
  - Client-Server 模式
    - Server 是主，Client 是次
    - Server 先运行，Client 后运行
    - 所有资源都在 Server 上
    - 问题：在请求超过阈值之后，对每个 Client 的服务能力会呈现断崖式下降（而非线性），体现为服务器崩溃
  - Peer-To-Peer 模式
    - 每一个端系统，同时是 Server 和 Client
      - 具体地，在某些其他端系统眼中是 Server，在另外一些端系统眼中是 Client
    - 优点：每一个 Peer 在上线之后，在消耗服务资源的同时，还贡献了服务资源

## 服务模式

### 面向连接的服务

> 注意：“面向连接”不是“有连接”
>
> “面向连接”是：状态只有应用知道、TCP 知道，而网络不知道。通信状态只在端系统中维护。
>
> “有连接”是：状态所有都知道。通信状态在中间节点中也维护。

**目标：**在端系统之间传输数据。

**面向连接的主要特征——握手：**也就是在数据传输之前**做好准备**

- 不仅是应用程序做好准备（i.e. 两者互相“打了招呼”），底层协议栈也做好了准备
  - e.g. 准备缓冲区、控制位置位、超时定时器设置好等等

#### 例子：TCP

TCP 是 Internet 上**面向连接**的服务。TCP 服务 [RFC 9293] 可以

- 可靠地（不重不错不漏）、按顺序地传送数据
  - 依靠确认和重传
- 流量控制
  - 发送方不会淹没接收方
- 拥塞控制
  - 当网络拥塞时，发送方降低发送速率

### 无连接的服务

#### 例子：UDP

TCP 是 Internet 上**无连接**的服务。TCP 服务 [RFC 9293] 可以

- 不可靠地、不一定按顺序地传送数据
- 无流量控制
- 无拥塞控制

作用：

1. 性能、带宽开销小
2. 为用户实现自己的可靠/流量控制/拥塞控制协议提供可能性

---

总结：

- 使用 TCP 的应用
  - HTTP, FTP, Telnet, SMTP
- 使用 UDP 的应用
  - 流媒体、远程会议、DNS、Internet 电话

# Lec 1.3：网络核心

网络核心就是**路由器的网状网络**。

## 数据的传输

数据在网络的传输方式有两种：电路交换、分组交换。

<img src="https://cdn.jsdelivr.net/gh/mtdickens/mtd-images/img/202402242333810.png" alt="image-20240224233328530" style="zoom: 67%;" />

### 电路交换

电路交换，就是为每个呼叫**预留**一条专有电路（如电话网），如图
<img src="https://raw.githubusercontent.com/MTDickens/mtd-images/main/img/202402241954795.png" alt="image" style="zoom: 67%;" />
另外，在电路交换中，网络资源（i.e. 带宽）被分成**片**

- 我们为一个呼叫分配一“片”。我们可以通过“频分”“时分”“波分”等方式，实现将一条线路分成多条小链路。
  <img src="https://cdn.jsdelivr.net/gh/mtdickens/mtd-images/img/202402242038862.png" alt="image-20240224203803800" style="zoom:33%;" />
- 举例：某一条线路的带宽为 1.536 Mbps，通过时分的方式分成 24 份（从而一片的带宽就是 64 Kbps）。一用户通过其中一片来传输 640 Kb(its) 的数据，其中建立连接的时间为 500 ms，且传播延迟不能忽略不计
  <img src="https://cdn.jsdelivr.net/gh/mtdickens/mtd-images/img/202402242334023.png" alt="image-20240224204508411" style="zoom:33%;" />

---

电路交换不适合用于计算机之间传输数据，是因为有以下缺点：

- 建立连接的时间太长（以秒为单位）
- 计算机的请求往往是突发式的，因此电路交换极大地浪费带宽

### 分组交换

- 将要传送的数据分成一个个范围：分组
- 将分组从一个路由器传到相邻路由器（hop），一段段最终从源端传到目标端
- 每段：采用链路的最大传输能力（带宽）

虽然有以下缺陷

- 数据以数据包为单位进行**存储-转发**，因此每个数据必须要等到整个数据包都传到了，才能进一步转发。如图
  <img src="https://cdn.jsdelivr.net/gh/mtdickens/mtd-images/img/202402242334871.png" alt="image-20240224233439732" style="zoom:50%;" />
  - 因此在每个节点处的延迟增加
- 数据包有排队时间
- 可能会有丢包

但是，我们通过分组，实现了最重要的**共享性**。

---

分组交换下的多路复用，其实是**统计多路复用**。也就是说，并没有明确规定那一段时间给哪一个源使用，而是按需分配。

### 电路交换和分组交换的定量分析

假设我们有 $N$ 个用户，每个用户在每一刻活跃的概率只有 $p \in [0,1]$，每个用户活跃时需要的带宽为为 100 Kbps，总带宽为 1 Gbps。

如果采用电路交换，那么，$N$ 最大为 10000。

如果采用分组交换，那么，在**任意时刻（或者一个足够小的时间段内）**，活跃用户的数量服从二项分布 $X \sim \operatorname{Bin}(N,p)$。我们不妨将其近似为正态分布 $\operatorname{N}(Np,Np(1-p))$。取 3-sigma，我们可以令 $Np + 3 \sqrt{Np(1-p)} < 10000$，即可保证在绝大多数时刻下，不会出现丢包的情况。

- 假设 $p=0.1$，那么， $N_{max} \approx 97194$。
  - 如果总带宽只有 1 Mbps，那么，大概只能只能 35 个用户（这里也不能近似为正态分布）。
- 在那些 3-sigma 之外的时间，我们就利用缓冲区来应对。此时，延迟就会增加。
  - 3-sigma 之外的时间服从分布 $T_{3\sigma} \sim \lim_{k \to \infty} \operatorname{Bin}(kT,0.27\%) / k = 0.27\%$

### 分组交换下的数据传输

在分组交换下，每个分组携带目标地址等 metadata，路由器根据目标地址进行路由。

这里的分组，称为**数据报（datagram）**。

- 同时，路由器**不维护**主机和主机之间通信的状态。它唯一要做的是就是：查表、转发！
- 对于维护状态的情况，我们使用的是**虚电路（Virtual Circuit）**
  - 端系统向网络发送指示虚电路启动与终止的报文，以及路由器之间传递的用于建立虚电路（即修改路由器表中的**连接状态**）的报文被称为信令报文，用来交换这些报文的协议常称为“信令协议”。

# Lec 1.4：接入网和物理媒体

接入网就是将网络边缘接入到网络核心的部分。

### 住宅接入：DSL + 调制解调器（modem）

很早以前，每家每户有一条电话线，可以保证传输 300 Hz ~ 3.4 kHz （人耳听力范围）的信号。

通过 modem，我们得以将 0,1 信号，调制（比如不同振幅 or 不同频率代表 0,1）成载波，通过电线传输，然后再解调成数字信号。从而，我们得以在电话线上传输数据。

Pitfall:

- 无法同时进行上网和打电话
- 带宽太小，只有 56 Kbps

---

后来，人们挖掘了 4 kHz 以上的频率用作上网，4 ~ 50 kHz 用于上行，50 ~ 1000 kHz 用于下行。从而使得上行可以达到 1 Mbps，下行可以达到 10 Mbps 左右。

### 住宅接入：电缆模式 + modem

不仅是电话线路，电视线路甚至电网也可以用于类似的接入。

- HFC: hybrid fiver coax
  - 非对称：最高 30Mbps 的下行传输速率，2 Mbps 的上行传输速率
- 线缆和光纤网络将各个家庭用户接入到 ISP 路由器
- 各用户**共享**到线缆头端的接入网络

### 接入网：家庭网络（Ethernet + WIFI）

如图，家庭路由器通过有线、无线的方式，借助 NAT 技术，在 cable/DSL modem 的转换下，将所有设备接入了互联网。同时配备了防火墙等高级功能。

<img src="https://cdn.jsdelivr.net/gh/mtdickens/mtd-images/img/202402251243598.png" alt="image-20240225124257925" style="zoom: 67%;" />

### 接入网：企业接入网络（Ethernet + WIFI）

<img src="https://cdn.jsdelivr.net/gh/mtdickens/mtd-images/img/202402251251922.png" alt="image-20240225125049372" style="zoom: 67%;" />

- 范围大
- 有多个接入点
- 多层交换机

### 广域无线接入：3/4/5G + LTE

（详见之后）

## 物理媒介

如图，前者是**导引型媒体**，后者是**非导引型媒体**。

<img src="https://cdn.jsdelivr.net/gh/mtdickens/mtd-images/img/202402251311473.png" alt="image-20240225131111891" style="zoom:60%;" /><img src="https://cdn.jsdelivr.net/gh/mtdickens/mtd-images/img/202402251310831.png" alt="image-20240225131046875" style="zoom:60%;" />

# Lec 1.5：Internet 结构和 ISP

> 互连网络结构：网络的网络

- 端系统通过**接入 ISPs** 接入互联网。
  - 住宅、公司、学校等

- 接入的 ISP 必须是互联的
  - 因为任意两个端系统可互相发送分组到对方

- ISP 的发展和演化受到经济、政治的影响，因此十分复杂

---

如图，如果 ISP 采用全连接的方式（如下图），那么

- 代价很高——$O(n^2)$
- 且不可扩展（扩展的代价为 $O(n)$）

<img src="https://cdn.jsdelivr.net/gh/mtdickens/mtd-images/img/202402251339856.png" alt="image-20240225133933652" style="zoom: 67%;" />

## 分层

因此，ISP 产生了分层（如下图），总体上分为 global ISP 和 regional ISP

<img src="https://cdn.jsdelivr.net/gh/mtdickens/mtd-images/img/202402251341898.png" alt="image-20240225134115230" style="zoom: 67%;" />

也就是说，将每个接入 ISP 都连接到全局 ISP（全局范围内覆盖）

同时，客户 ISPs 和提供者 ISPs 有经济合约

## 竞争与合作

**竞争：**但是，一个 global ISP 进行垄断肯定是不行的（政治/经济因素），因此，世界上有很多个 global ISPs。

<img src="https://cdn.jsdelivr.net/gh/mtdickens/mtd-images/img/202402251344737.png" alt="image-20240225134431717" style="zoom:67%;" />

**合作：**同时，每个 global ISP 都有一定的客户。因此，不同 ISPs 为了实现互联，就在之间建立了**互联**。

- 这些互联往往是**对等互联（peering link）**，也就是双方都不花钱的互联
- 有时候，ISP 为了方便与多个 ISPs 互联，就接入了 IXP

<img src="https://cdn.jsdelivr.net/gh/mtdickens/mtd-images/img/202402251356512.png" alt="image-20240225135557850" style="zoom:67%;" />

## 业务细分

并不是所有的端用户直接接入 global ISP。大多数端用户还是先接入 regional ISP（如图）。

这样，端用户是 regional ISP 的客户，而 regional ISP 才是 global ISP 的客户。

<img src="https://cdn.jsdelivr.net/gh/mtdickens/mtd-images/img/202402251357206.png" alt="image-20240225135744278" style="zoom:67%;" />

## 互联网内容提供商（Internet Content Provider）

经常，互联网内容提供商为了

- 降低接入 ISP 的费用
- 提高用户体验
  - 主要是降低延迟

就会

- 在全球特定地区（e.g. 在重要的 ISP 机房附近）建立数据中心机房
  - 降低延迟
- 通过自建/租用的专用线缆，在各大机房之间传输数据
  - 和 ISP 谈价格的时候，由于 ISP 不需要负担太多远距离传输，因此价格便宜一些

<img src="https://cdn.jsdelivr.net/gh/mtdickens/mtd-images/img/202402251410688.png" alt="image-20240225141033701" style="zoom:67%;" />

## 总体结构

![image-20240225141221763](https://cdn.jsdelivr.net/gh/mtdickens/mtd-images/img/202402251412104.png)

## 层次模型

### Tier 1 ISP

- 国家/国际覆盖，速率极高
  - 不过，通常来说，点比较少

- 直接与其他 Tier 1 ISP 相连
  - 通过 peering link/IXP 接入

- 与大量的 Tier 2 ISP 和其他客户网络相连
  - 连接点的名称是 Point of Presence (POP)

### Tier 2 ISP

向上给 Tier 1 ISP 交钱（有时也 peering），向下收 Tier 3 ISP 的费用，和 fellow  Tier 2 ISP 经常 peering。

### Tier 3 ISP

向上给 Tier 1/2 ISP 交钱，向下收 local ISP 的费用。

<img src="https://cdn.jsdelivr.net/gh/mtdickens/mtd-images/img/202402251425332.png" alt="image-20240225142509782" style="zoom:67%;" />

## ISP 之间的接入方式

<img src="https://cdn.jsdelivr.net/gh/mtdickens/mtd-images/img/202402251429745.png" alt="image-20240225142936306" style="zoom: 80%;" />

# Lec 1.6：分组延时、丢失和吞吐量

## 分组延时

在路由器缓冲区的分组队列

- 分组到达链路的速率，超过了链路输出的能力
- 分组等待排到队头、被传输

从而产生了排队延时。

除了排队延时以外，还有处理延时（i.e. 处理数据包的延时）、传输延时（i.e. 将**整个**数据包传出/传入主机的时间）和传播延时（i.e. 数据包在两台主机之间传输的时间）

其中：

- 传输延时 $d_\text{trans} = L / R$，取决于数据包大小 $L$ 和带宽 $R$
- 传播延时 $d_\text{prop} = D / c'$，取决于距离 $D$ 和介质内光速 $c'$
  - 一般为几微秒到几百毫秒
- 排队延时一定意义上是随机的，取决于拥塞程度
- 处理延时一般为微秒数量级或者更少，很多情况下可以忽略不计

总延时等于四个延时之和：
$$
d_\text{nodal} = d_\text{proc} + d_\text{queue} + d_\text{trans} + d_\text{prop}
$$

---

我们可以粗略地分析一下排队延时。

假设

- **到达以速率 λ 遵循泊松过程**，并将系统状态从 i 移动到 i + 1。
  - 实际上不是泊松过程。这是最大的问题

- **服务时间是确定性时间 D**（服务速率为 μ = 1/D）。
  - 这是准确的
    - 不过，需要考虑传播延时和处理延时之和
- 服务器按照先到先服务 (FCFS) 原则依次为队列前端的实体提供服务。服务完成后，实体离开队列，系统中的实体数量减少 1。
  - 这是准确的
- **缓冲区大小无限**，因此对可以容纳的实体数量没有限制。
  - 缓冲区大小其实是有限的，当然我们可以以后再讨论

那么，我们就可以套用排队论中的 M/D/1 模型（当然你也可以自己用 Continuous-Time Markov Chain 来分析），可知平均等待时间：
$$
\omega_Q = \frac{D \rho}{2(1-\rho)}
$$
其中

- 载荷 $\rho = \frac \lambda \mu = \lambda D \approx \lambda d_\text{prop} = \frac {\lambda L} R$

从而，

<img src="https://cdn.jsdelivr.net/gh/mtdickens/mtd-images/img/202402251845402.png" alt="image-20240225184502269" style="zoom:50%;" />

## 延时及（去程）路由测试工具：Traceroute

Traceroute 的大致原理，就是

- **逐次发送 TTL (Time To Live) 为从 1 到 MAX_HOP 的数据包**
  - 数据包传统上是 ICMP 协议
- （路由器）主机接收到数据包后，会 TTL -= 1。**如果发现 TTL = 0，就会丢弃，并且向源主机返回一个错误信息**
  - 从而，源主机就可以计算出**和中间的路由器**往返时间
    - 称为 RTT（Round Trip Time）
- 目标主机需要另外考虑。我们可以**向其一个随机高位端口进行请求**。大概率那个端口是没有进程占用的。从而，**主机会返回一个 ICMP 数据包，通知我们端口错误的信息**
  - 从而，源主机就可以计算出**和目标主机**往返时间

## 丢包和重传

当路由器的缓冲区满了之后，或者 QoS 等等，就会导致丢包。

对于丢包，我们有三种重传模式：

1. **上一跳重传**
   - 如果链路的物理媒介本身不可靠，往往链路本身会重传（也就是“**上一跳重传**”），从而进行**亡羊补牢**
     - 比如各种非引导型介质：WIFI、……
2. **源主机重传**
   - 如果链路的物理媒介本身可靠，往往链路本身不会重传
     - 比如各种非引导型介质：以太网、……
   - 此时，如果仍然希望重传，那么就必须要**源主机重传**
     - 比如利用 TCP
3. **不重传**
   - 同上，除了使用的是 UDP 协议

## 吞吐量

源主机 A 到目标主机 B 链路中的**瓶颈带宽**，很大程度上影响了 A 到 B 的吞吐量。