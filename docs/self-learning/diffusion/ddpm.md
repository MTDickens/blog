> author: Gemini 2.5 Pro 0605 & mtdickens1998
> 
> prompt: 从上往下推一遍，像一个大学老师一样，循循善诱、循序渐进将这篇论文的内容交给我，保证让我看懂。你的格式需要类似网上常见的 markdown 技术博客。  
>   
> 有几点注意事项：  
> 1. 对于一些非常困难的步骤（if you think it's too difficult）但是它又不那么重要，你可以一笔带过（但是要显式告诉我），但是在 appendix 中给我仔细讲讲  
> 2. 对于数学，用 $...$。同时，对于 $...$ 中的所有公式，都要写清楚里面的符号的意思——I mean，需要像老师讲课一样写清楚，也就是保证零基础同学看一眼就能看明白  
> 3. 除了讲清楚推导步骤以外，还要讲清楚各种 intuition。此外，你还要考虑我们可能存在的疑问（包括推导上的，以及 intuition 上的），列出来它们，并给我们稍微解答一下  
>   
> 你只能假设我学过微积分、线性代数以及初等概率论。其它我都没学过。

## 零基础读懂 Diffusion Model？带你逐行精读DDPM

你好，欢迎来到今天的深度学习研讨课。我是你的助教 Aurelle。今天要拆解的这篇论文，是生成模型领域的一座里程碑：来自 UC Berkeley 的 [Denoising Diffusion Probabilistic Models (DDPM)](https://arxiv.org/abs/2006.11239)。

在它之后，各种强大的图像生成模型（比如 Midjourney, Stable Diffusion 的底层）都或多或少借鉴了它的思想。所以，读懂它，对于理解现代 AI 的图像生成能力至关重要。

我们的目标是：不仅看懂，更要理解其精髓。

### 核心思想：先“破坏”再“修复”

在深入数学细节之前，我们先用一句话抓住 Diffusion 模型的灵魂：**它通过一个“先加噪，再降噪”的过程来学习生成数据。**

想象一下：

1.  你有一张高清的猫咪图片（这是我们的目标数据 $x_0$）。
2.  **前向过程 (Forward Process)**：你开始对这张图片反复地、轻微地撒上一点点“高斯噪声”。每撒一次，图片就模糊一点。重复几百上千次（比如 $T$ 次）后，这张原始的猫咪图片最后就变成了一幅完全看不出内容的、纯粹的随机噪声图（$x_T$）。这个过程就像是把一块精美的雕塑放在风中，任其慢慢风化成一块普通的石头。
3.  **逆向过程 (Reverse Process)**：现在，神奇的部分来了。如果我们能教会一个神经网络模型，让它学会上面那个“风化”过程的**逆操作**，也就是，给它一块风化后的石头（$x_t$），它能预测出石头在被风化前一点点（$x_{t-1}$）的样子。那么，只要我们不断地重复这个“修复”或“去噪”的过程，最终是不是就能从一块完全随机的石头（纯噪声 $x_T$）开始，一步步逆推，最终“雕刻”出一块精美的雕塑（一张全新的、逼真的猫咪图片）呢？

![Diffusion Process](https://gitlab.com/mtdickens1998/mtd-images/-/raw/main/pictures/2025/06/12_20_38_51_DDPM.png)


这就是 Diffusion Model 的全部哲学。整个 DDPM 论文，就是围绕着如何用数学语言精确地描述这两个过程，并设计出一个可训练的神经网络模型来学习这个“修复”技能。

下面，我们正式进入论文的数学世界。

---

### 第一站：前向过程 $q$ (Forward Process) - 如何优雅地“破坏”

前向过程，也叫扩散过程 (diffusion process)，是把数据 $x_0$ 逐渐变成噪声 $x_T$ 的过程。DDPM 选择了一种非常简单和数学上很方便的方式：每一步都添加少量的高斯噪声。

这个过程被定义为一个马尔可夫链 (Markov chain)，意思是 $x_t$ 的状态只依赖于它的前一个状态 $x_{t-1}$。

具体的加噪公式是：
$q(x_t | x_{t-1}) := \mathcal{N}(x_t; \sqrt{1 - \beta_t} x_{t-1}, \beta_t \mathbf{I})$

**公式解读**：

*   $q(x_t | x_{t-1})$：表示在给定 $x_{t-1}$ 的条件下，$x_t$ 的概率分布。
*   $\mathcal{N}(...; \mu, \Sigma)$：代表一个高斯分布（正态分布）。第一个参数是变量，分号后面是均值 $\mu$ 和协方差矩阵 $\Sigma$。
*   $x_t$：第 $t$ 步加噪后的图像。你可以把它想象成一个向量，每个元素代表一个像素值。
*   $x_{t-1}$：第 $t-1$ 步的图像。
*   $\beta_t$：一个非常小的正常数，它是一个超参数，由我们自己设定。它代表在第 $t$ 步加入噪声的“强度”或“方差”。在 DDPM 中，$\beta_t$ 会从 $\beta_1=10^{-4}$ 慢慢增加到 $\beta_T=0.02$。
*   $\sqrt{1 - \beta_t} x_{t-1}$：这是高斯分布的**均值**。我们先把上一时刻的图像 $x_{t-1}$ 稍微缩小一点。
*   $\beta_t \mathbf{I}$：这是高斯分布的**协方差**。$\mathbf{I}$ 是单位矩阵，这意味着我们给每个像素都加上了方差为 $\beta_t$ 的、独立的高斯噪声。

> **🤔 你可能会问 #1：为什么要在均值项里乘上 $\sqrt{1 - \beta_t}$ 呢？直接加噪声不行吗？**
>
> **答：** 这是个非常好的细节问题！这样做是为了**保持数据尺度的稳定**。想象一下，如果 $\beta_t$ 很小，$\sqrt{1-\beta_t} \approx 1 - \frac{1}{2}\beta_t$。如果我们假设 $x_{t-1}$ 的方差是 1，那么 $x_t$ 的方差就是 $(\sqrt{1-\beta_t})^2 \cdot 1 + \beta_t = 1 - \beta_t + \beta_t = 1$。也就是说，通过这个缩放因子，我们能让每一步加噪后的数据方差大致保持不变，这有利于模型训练的稳定性。

#### 一步到位：从 $x_0$ 直接跳到 $x_t$

一步一步加噪太慢了。幸运的是，高斯分布有一个绝佳的特性：**高斯分布的叠加还是高斯分布**。这使得我们可以推导出一个从原始图像 $x_0$ 直接得到任意时刻 $t$ 的噪声图像 $x_t$ 的公式。

我们定义 $\alpha_t := 1 - \beta_t$ 和 $\bar{\alpha}_t := \prod_{s=1}^{t} \alpha_s$ (累积乘积)。经过推导（这里用到了高斯分布的重参数技巧），我们可以得到：

$q(x_t | x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t)\mathbf{I})$

**公式解读**：

*   $\bar{\alpha}_t$：从第 1 步到第 $t$ 步的 $\alpha$ 的累积乘积。因为它是一堆小于 1 的数相乘，所以当 $t$ 越大，$\bar{\alpha}_t$ 越接近 0。
*   $\sqrt{\bar{\alpha}_t} x_0$：均值。随着 $t$ 增大，$\bar{\alpha}_t \to 0$，所以原始图像 $x_0$ 对均值的影响越来越小。
*   $(1 - \bar{\alpha}_t)\mathbf{I}$：协方差/方差。随着 $t$ 增大，$(1 - \bar{\alpha}_t) \to 1$，所以噪声的方差越来越大，最终接近 1。

这个公式至关重要！它意味着，在训练时，我们不需要真的去循环 $t$ 次。我们可以随机选择一个时刻 $t$，然后用这个公式直接从 $x_0$ 生成 $x_t$ 的样本，这大大提高了训练效率。

当 $T$ 足够大时（比如 DDPM 里的 1000），$\bar{\alpha}_T \approx 0$，此时 $q(x_T | x_0) \approx \mathcal{N}(x_T; 0, \mathbf{I})$，也就是一个标准的、纯粹的高斯噪声，几乎不包含 $x_0$ 的任何信息。“破坏”完成！

---

### 第二站：逆向过程 $p_\theta$ (Reverse Process) - 如何艺术地“修复”

现在，我们要学习“修复”的艺术了。也就是，我们想要求解 $p(x_{t-1} | x_t)$——在已知 $t$ 时刻图像 $x_t$ 的情况下，$t-1$ 时刻图像 $x_{t-1}$ 的概率分布。

但这里有个大问题：**我们无法直接计算 $p(x_{t-1} | x_t)$**。因为它需要用到整个数据集的分布信息，这是极其复杂的，我们根本不知道。

怎么办？机器学习的经典套路来了：**用一个神经网络去近似它！**

我们定义一个由参数 $\theta$ 构成的神经网络模型，用它来近似这个未知的逆向过程。我们把这个模型记为 $p_\theta$。

$p_\theta(x_{t-1} | x_t) := \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))$

**公式解读**：

*   $p_\theta(x_{t-1} | x_t)$：我们模型化的逆向过程。它也是一个高斯分布。
*   $\mu_\theta(x_t, t)$：一个神经网络。它的输入是当前时刻的噪声图像 $x_t$ 和时刻 $t$，输出是预测的 $t-1$ 时刻图像的**均值**。
*   $\Sigma_\theta(x_t, t)$：另一个神经网络（或固定值）。它输出预测的**协方差**。

在 DDPM 中，作者发现，将协方差矩阵 $\Sigma_\theta$ 固定为一个与 $\beta_t$ 相关的常量（比如 $\Sigma_\theta(x_t, t) = \sigma_t^2 \mathbf{I}$），而不是让网络去学习它，效果也很好，甚至更稳定。所以，**我们模型的全部任务，就集中在了如何准确地预测那个均值 $\mu_\theta(x_t, t)$**。

这个预测均值的神经网络，就是 DDPM 的核心。论文中使用了一个带有 Attention 机制的 U-Net 结构，但我们暂时不用关心网络结构细节，只需知道它是一个函数 $\mu_\theta(x_t, t)$ 就行。

---

### 第三站：连接两个过程 - 如何训练模型？

我们有了“破坏”的前向过程 $q$ 和“修复”的逆向模型 $p_\theta$。怎么让 $p_\theta$ 学得像样呢？

我们的目标是让模型生成的图像尽可能逼真。在概率模型中，这通常通过**最大化数据的对数似然** (log-likelihood) 来实现。也就是说，我们希望我们定义的整个生成过程 $p_\theta(x_0)$，对于真实数据 $x_0$ 来说，其概率尽可能大。

但是， $p_\theta(x_0) = \int p_\theta(x_{0:T}) dx_{1:T}$ 涉及到对所有可能噪声路径的积分，这是个维度高到无法计算的积分。

这里，论文引入了一个在变分推断（Variational Inference）中非常核心的工具：**变分下界 (Variational Lower Bound, VLB)**，也叫证据下界 (Evidence Lower Bound, ELBO)。

> **⚠️ 预警：前方高能，但我们会用直觉来导航！**
>
> 这个 VLB 公式的推导是这篇论文里最劝退的数学部分。它涉及到 KL 散度、琴生不等式等概念。**为了不打断主线思路，我们这里先给出一个“直觉版”的解释，并直接看它的最终结果**。如果你对完整的推导感兴趣，我把它放在了文末的 **附录A** 中。

**直觉版解释：**
我们虽然不能直接最大化 $\log p_\theta(x_0)$，但我们可以找到一个它的“下界” $L_{VLB}$，并且这个下界是可计算、可优化的。我们通过最大化这个下界 $L_{VLB}$，来间接地抬高原始的 $\log p_\theta(x_0)$。

经过一番推导（详见附录A），这个下界可以写成一系列项的和（论文中的公式 5）：

$L_{VLB} = \mathbb{E}_q[\underbrace{D_{KL}(q(x_T|x_0) || p(x_T))}_{L_T} + \sum_{t=2}^{T} \underbrace{D_{KL}(q(x_{t-1}|x_t, x_0) || p_\theta(x_{t-1}|x_t))}_{L_{t-1}} - \underbrace{\log p_\theta(x_0|x_1)}_{L_0}]$

**公式解读**：

*   $D_{KL}(q || p)$：KL 散度。它衡量两个概率分布 $q$ 和 $p$ 的差异程度。$D_{KL} \ge 0$，当且仅当 $q$ 和 $p$ 完全相同时取 0。我们的目标就是让模型分布 $p_\theta$ 去逼近真实分布 $q$，也就是最小化这些 KL 散度项。
*   $L_T$: 最后一项，衡量加噪到 $T$ 时刻的分布与标准正态分布的差异。由于我们设计得很好，这一项基本是个可以忽略的常数。
*   $L_0$: 最后一小步去噪，从 $x_1$ 生成 $x_0$ 的过程。它是一个由离散解码器定义的项。
*   $L_{t-1}$: **这是最核心的训练信号来源！** 它说，对于每一步 $t$，我们的模型 $p_\theta(x_{t-1}|x_t)$ 应该要和 $q(x_{t-1}|x_t, x_0)$ 尽可能地像。

> **🤔 你可能会问 #2：等等！$q(x_{t-1}|x_t, x_0)$ 是什么？之前不是说逆向过程 $p(x_{t-1}|x_t)$ 不能求吗？**
>
> **答：** 绝妙的问题！我们确实求不出 $p(x_{t-1}|x_t)$，因为它依赖于整个未知的数据集。但是！如果我们**额外给定原始图像 $x_0$**，那么这个后验概率 (posterior) $q(x_{t-1}|x_t, x_0)$ 是**可以被精确计算**的！
>
> 这是因为 $q(x_{t-1}|x_t, x_0)$ 同时依赖于前向过程 $q(x_t|x_{t-1})$ 和 $q(x_{t-1}|x_0)$，而这两个我们都是知道的（都是高斯分布）。利用贝叶斯定理，我们可以推导出 $q(x_{t-1}|x_t, x_0)$ 也是一个高斯分布，并且它的均值和方差都有具体的解析表达式（见论文公式 6 和 7）。
>
> 这就提供了一个完美的“**训练靶子**”！在训练时，我们有 $x_0$，所以我们知道 $q(x_{t-1}|x_t, x_0)$ 的确切形式。我们的任务就是训练神经网络 $\mu_\theta(x_t, t)$ 去拟合这个已知的、理想的均值。

---

### 第四站：DDPM 的神来之笔 - 简化目标函数

虽然我们找到了训练目标（最小化 $L_{t-1}$ 的 KL 散度），但它仍然有点复杂。KL 散度涉及到两个高斯分布的均值和方差，直接优化它，不如把它展开。

$L_{t-1} = \mathbb{E}_q \left[ \frac{1}{2\sigma_t^2} || \tilde{\mu}_t(x_t, x_0) - \mu_\theta(x_t, t) ||^2 \right] + C$

这里的 $\tilde{\mu}_t(x_t, x_0)$ 就是我们上面说的那个“训练靶子”——$q(x_{t-1}|x_t, x_0)$ 的真实均值。这个公式告诉我们，训练的核心就是**让我们的神经网络预测的均值 $\mu_\theta$ 去逼近真实的均值 $\tilde{\mu}_t$**。

现在，DDPM 的作者们做了一个**极其漂亮**的代数变形和重新参数化 (reparameterization)。

1.  回忆一下，前向过程是 $x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon$，其中 $\epsilon \sim \mathcal{N}(0, \mathbf{I})$ 是注入的随机噪声。
2.  经过一些代数推导（见论文公式 10 和 11），作者们发现，预测均值 $\mu_\theta$ **等价于** 预测当初加入的噪声 $\epsilon$。
3.  他们将神经网络 $\mu_\theta(x_t, t)$ 重新设计成一个**预测噪声**的神经网络 $\epsilon_\theta(x_t, t)$。
    *   旧思路：网络输入 $x_t$，直接输出均值 $\mu_\theta$。
    *   新思路：网络输入 $x_t$，输出预测的噪声 $\epsilon_\theta$。然后通过一个固定的计算公式，从 $x_t$ 和 $\epsilon_\theta$ 得到均值 $\mu_\theta$。

当把这个新的噪声预测模型 $\epsilon_\theta$ 代入到损失函数 $L_{t-1}$ 后，经过一番化简，奇迹发生了！损失函数变成了一个异常简洁和优美的形式：

$L_{simple}(\theta) := \mathbb{E}_{t, x_0, \epsilon} \left[ ||\epsilon - \epsilon_\theta(\sqrt{\bar{\alpha}_t}x_0 + \sqrt{1 - \bar{\alpha}_t}\epsilon, t)||^2 \right]$

**公式解读**：

*   $\epsilon$：在 $t$ 时刻，我们从 $x_0$ 生成 $x_t$ 时，随机采样的**真实噪声**。
*   $\epsilon_\theta(...)$：我们的神经网络。输入是噪声图像 $x_t$（这里用它的定义展开了）和时刻 $t$。输出是网络**预测的噪声**。
*   $||\cdot||^2$：L2 范数，也就是均方误差 (MSE)。

这个简化后的目标函数，就是 DDPM 的核心算法。它的训练流程变得非常清晰：

1.  从你的数据集中随机抽取一张真实图片 $x_0$。
2.  随机选择一个时间步 $t$ (从 1 到 T)。
3.  从标准高斯分布中随机采样一个噪声 $\epsilon$。
4.  通过 $x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon$ 生成该时刻的噪声样本 $x_t$。
5.  将 $x_t$ 和 $t$ 送入我们的 U-Net 模型 $\epsilon_\theta$。
6.  计算模型预测的噪声 $\epsilon_\theta$ 和真实的噪声 $\epsilon$ 之间的均方误差。
7.  使用梯度下降，更新网络参数 $\theta$，以减小这个误差。

**这个过程本质上就是在训练一个“降噪自编码器” (Denoising Autoencoder)。** 作者发现，这个简单的目标函数不仅在实现上更简单，而且在实验效果上比直接优化 VLB 更好，能生成质量更高的图片。

---

### 总结与回顾

好了，同学，我们已经走完了 DDPM 最核心的旅程。让我们回顾一下：

1.  **构想**：通过模拟一个“加噪”再“去噪”的过程来生成图像。
2.  **前向过程**：定义了一个数学上很方便的、逐步加高斯噪声的马尔可夫链。它有一个很好的性质，可以从 $x_0$ 一步跳到任意 $x_t$。
3.  **逆向过程**：由于真实的逆向过程不可知，我们用一个神经网络 $p_\theta$ 去近似它。
4.  **训练目标**：通过最大化变分下界 (VLB) 来训练模型。其核心是让模型的每一步逆向操作，都去拟合一个已知的、真实的逆向后验分布 $q(x_{t-1}|x_t, x_0)$。
5.  **DDPM 的创新**：通过巧妙的重新参数化，将复杂的 VLB 目标函数简化为了一个非常直观的**噪声预测**任务。整个训练过程就变成了让一个 U-Net 模型学会如何从一张加噪图片中剥离出噪声。

一旦模型 $\epsilon_\theta(x_t, t)$ 训练好了，我们如何生成一张新图片呢？非常简单：

1.  从一个纯粹的高斯噪声 $x_T \sim \mathcal{N}(0, \mathbf{I})$ 开始。
2.  从 $t=T$ 开始，一步步往前走，直到 $t=1$：
    *   将当前的 $x_t$ 和 $t$ 输入模型，得到预测的噪声 $\epsilon_\theta(x_t, t)$。
    *   使用这个预测的噪声，通过一个固定的公式计算出 $x_{t-1}$ 的均值（即 $\mu_\theta$）。
    *   从以该均值为中心的高斯分布中采样得到 $x_{t-1}$ (如果 $t>1$，还要加上一点随机噪声；如果 $t=1$，则不加)。
3.  最后得到的 $x_0$ 就是我们生成的新图片！

希望这次讲解能让你对 DDPM 有一个清晰而深入的理解。这篇论文的思想非常优雅，它将一个复杂的生成任务，分解成了一系列简单的、可控的降噪步骤，为后续的生成模型发展铺平了道路。

***

### 附录：那些被我们“一笔带过”的数学细节

#### 附录A：变分下界 (VLB) 是如何推导出来的？

我们的目标是最大化 $\log p_\theta(x_0)$。

$\log p_\theta(x_0) = \log \int p_\theta(x_{0:T}) dx_{1:T}$

我们引入我们已知的分布 $q(x_{1:T}|x_0)$，在积分号内同乘同除它（这个操作不改变等式）：

$= \log \int p_\theta(x_{0:T}) \frac{q(x_{1:T}|x_0)}{q(x_{1:T}|x_0)} dx_{1:T}$

$= \log \mathbb{E}_{q(x_{1:T}|x_0)} \left[ \frac{p_\theta(x_{0:T})}{q(x_{1:T}|x_0)} \right]$

这里用到了期望的定义 $\mathbb{E}_{q(x)}[f(x)] = \int f(x)q(x)dx$。

现在，我们使用**琴生不等式 (Jensen's Inequality)**。对于一个凹函数（比如 $\log(x)$），有 $\log(\mathbb{E}[Y]) \ge \mathbb{E}[\log(Y)]$。所以：

$\ge \mathbb{E}_{q(x_{1:T}|x_0)} \left[ \log \frac{p_\theta(x_{0:T})}{q(x_{1:T}|x_0)} \right] = L_{VLB}$

这就是变分下界。我们现在来拆解这个 $L_{VLB}$。

$p_\theta(x_{0:T}) = p(x_T) \prod_{t=1}^T p_\theta(x_{t-1}|x_t)$ （根据逆向过程的马尔可夫链定义）
$q(x_{1:T}|x_0) = \prod_{t=1}^T q(x_t|x_{t-1})$ （根据前向过程的马尔可夫链定义）

代入 $L_{VLB}$ 中的 log 项：

$\log \frac{p_\theta(x_{0:T})}{q(x_{1:T}|x_0)} = \log \frac{p(x_T) \prod_{t=1}^T p_\theta(x_{t-1}|x_t)}{ \prod_{t=1}^T q(x_t|x_{t-1})}$
$= \log p(x_T) + \sum_{t=1}^T \log \frac{p_\theta(x_{t-1}|x_t)}{q(x_t|x_{t-1})}$

这里用贝叶斯定理 $q(x_t|x_{t-1}) = \frac{q(x_{t-1}|x_t, x_0) q(x_t|x_0)}{q(x_{t-1}|x_0)}$，代入后可以进行拆分（这一步推导比较繁琐），最终可以整理成 KL 散度的形式。一个更简洁的拆解方式是：

$\log \frac{p_\theta(x_{0:T})}{q(x_{1:T}|x_0)} = \log \frac{p_\theta(x_0) \prod_{t=1}^T p_\theta(x_t|x_{t-1})}{q(x_1|x_0) \prod_{t=2}^T q(x_t|x_{t-1})} = ...$

...经过一系列的拆分和重组，最终会得到论文中公式(5)的形式，即：

$L_{VLB} = \mathbb{E}_q[ D_{KL}(q(x_T|x_0) || p(x_T)) + \sum_{t=2}^T D_{KL}(q(x_{t-1}|x_t,x_0) || p_\theta(x_{t-1}|x_t)) - \log p_\theta(x_0|x_1) ]$
这可以写成KL散度的形式。

#### 附录B: $q(x_{t-1}|x_t, x_0)$ 的推导

根据贝叶斯定理，$q(x_{t-1}|x_t, x_0) \propto q(x_t|x_{t-1}, x_0) q(x_{t-1}|x_0)$。
因为前向过程是马尔可夫的，$q(x_t|x_{t-1}, x_0) = q(x_t|x_{t-1})$。
所以 $q(x_{t-1}|x_t, x_0) \propto q(x_t|x_{t-1}) q(x_{t-1}|x_0)$。

我们知道：

$q(x_t|x_{t-1}) = \mathcal{N}(x_t; \sqrt{\alpha_t} x_{t-1}, (1-\alpha_t)\mathbf{I})$
$q(x_{t-1}|x_0) = \mathcal{N}(x_{t-1}; \sqrt{\bar{\alpha}_{t-1}} x_0, (1-\bar{\alpha}_{t-1})\mathbf{I})$

我们知道高斯分布的概率密度函数形式为 $f(x) \propto \exp(-\frac{1}{2} \frac{(x-\mu)^2}{\sigma^2})$。
将上面两个高斯分布的密度函数相乘，只看指数部分，它是一个关于 $x_{t-1}$ 的二次函数。通过配方法，我们可以把它重新整理成 $\exp(-\frac{1}{2} \frac{(x_{t-1} - \tilde{\mu})^2}{\tilde{\beta}})$ 的形式。
配方后的均值 $\tilde{\mu}$ 和方差 $\tilde{\beta}$ 就是论文中给出的 $\tilde{\mu}_t(x_t, x_0)$ 和 $\tilde{\beta}_t$ 的表达式。这证明了后验分布也是一个高斯分布，并且其参数是可解的。
