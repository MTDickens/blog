# 扩散模型全面学习路线图：从基石到2025年技术前沿

## 引言

生成式人工智能领域经历了一次范式转移，其标志是一类新型模型的崛起——它们能够以空前的保真度和多样性合成数据。在这之中，**扩散模型（Diffusion Models）** 已成为主导力量，在众多领域频繁超越了诸如生成对抗网络（GANs）和变分自编码器（VAEs）等成熟框架。它们最初在图像生成领域取得了卓越成功，随后其原理被迅速扩展，为视频合成、3D内容创作、音频制作乃至蛋白质工程和材料科学等复杂科学发现领域带来了革命。扩散模型的吸引力不仅在于其顶尖的生成效果，还在于其相对稳定的训练动态，这成功规避了GANs训练中常见的模式崩溃和训练不稳定性等陷阱。

本文档为掌握扩散模型提供了一份全面且具有前瞻性的学习路线图。它旨在引导读者从基础的数学原理出发，一路探索至2024年和2025年的前沿研究阵地。我们的旅程始于深入探讨该领域的两大理论支柱：**去噪扩散概率模型（DDPMs）** 和 **基于分数的生成模型（Score-Based Generative Modeling）**，并最终通过**随机微分方程（SDEs）** 的语言将它们统一起来。接着，路线图将描绘一系列为解决模型初代主要缺陷——采样速度缓慢——而发展出的技术的激烈而迅速的演进，涵盖从确定性采样器、先进的常微分方程（ODE）求解器到知识蒸馏这一模型压缩新范式的所有内容。

随后，路线图将探索另一条并行的演进轨迹——**基于流的（Flow-Based）模型**，这类模型将生成问题重塑为直接的“传输”问题。我们还将审视从卷积U-Net到可扩展Transformer的关键架构转变，这一转变催生了像OpenAI的Sora和Stability AI的Stable Diffusion 3这样的巨型模型。在此之后，本文将深入探讨控制与定制化的生态系统，分析诸如无分类器引导（Classifier-Free Guidance）、ControlNet和低秩适应（LoRA）等技术，这些技术将生成器转变为可操控的实用工具。报告的后半部分将聚焦于扩散模型在不同模态上的扩展，并设有专门章节探讨在视频、音频、3D和科学应用领域的最新突破。最后，我们将眺望地平线，讨论模型对齐、新数据范式、实用软件生态系统中的最新趋势，以及那些将塑造该领域未来的关键开放性研究问题。

本路线图面向具备扎实技术基础的读者，如研究生、机器学习研究员或资深AI工程师。我们假定读者已掌握微积分、线性代gebra、概率论以及深度学习的基础知识，包括神经网络和Transformer架构。通过遵循这条结构化的路径，读者不仅能理解扩散模型的工作原理，还能掌握驱动其进步的创新因果链，从而获得应用这些强大模型并为其未来发展做出贡献的知识。

## 第一部分：扩散模型的基石

现代扩散模型的理论基础沿着两条并行但深度关联的路径演进。第一条路径植根于概率建模和潜变量，其典范是**去噪扩散概率模型（DDPMs）**。第二条路径源于统计物理学和分数匹配（Score Matching），并最终发展为使用**随机微分方程（SDEs）** 的强大连续时间范式。理解这两种视角及其最终的统一，对于完全掌握该领域至关重要，因为这种综合不仅提供了一种更通用的数学语言，还直接解锁了众多强大的新功能。

### 1.1 缘起：去噪扩散概率模型 (DDPM)

将扩散模型推向主流的工作是Ho、Jain和Abbeel在2020年发表的《Denoising Diffusion Probabilistic Models》。这篇论文首次证明，这类模型生成的图像质量可以与顶尖的GAN相媲美，甚至在某些情况下超越了它们。DDPM被构建为一种潜变量模型，其灵感来源于非平衡热力学。其核心机制包含两个相反的过程：一个固定的**前向过程**，通过添加噪声来系统性地破坏数据；以及一个学习的**反向过程**，从噪声中重建数据。

#### 前向过程 (扩散过程)

前向过程，也称为扩散过程，是一个固定的、不涉及任何学习的程序。它被定义为一个马尔可夫链，在 $T$ 个离散的时间步上，逐步向数据中注入少量高斯噪声。从真实数据分布 $q(x_0)$ 中取出一个干净的样本 $x_0$（例如一张图片）开始，该过程生成一系列越来越嘈杂的潜变量 $x_1, x_2, \dots, x_T$。每一步 $t$ 的转移由以下公式给出：

$q(x_t | x_{t-1}) := \mathcal{N}(x_t; \sqrt{1 - \beta_t}x_{t-1}, \beta_t I)$

**公式解释:**
* 这个公式描述了前向加噪过程中的单步操作。
* $x_{t-1}$ 是在第 $t-1$ 步的图像。
* $x_t$ 是在第 $t$ 步的图像。
* $q(x_t | x_{t-1})$ 表示在给定 $x_{t-1}$ 的条件下，$x_t$ 的概率分布。
* $\mathcal{N}(\cdot; \mu, \Sigma)$ 代表一个高斯（正态）分布，其均值为 $\mu$，协方差为 $\Sigma$。
* $\beta_t$ 是一个预先设定的、在 $(0, 1)$ 之间取值的小常数，代表在第 $t$ 步加入噪声的方差（即噪声的强度）。$\{\beta_t\}_{t=1}^T$ 共同构成了一个“噪声时间表”。
* $\sqrt{1 - \beta_t}x_{t-1}$ 是新分布的均值。可以看到，每一步都会将前一步的图像 $x_{t-1}$ 的尺度稍微缩小。
* $\beta_t I$ 是新分布的协方差矩阵，$I$ 是单位矩阵。这意味着我们添加的是各项同性的高斯噪声。
* **总体而言，这个公式的含义是：第 $t$ 步的噪声图像 $x_t$ 是通过对第 $t-1$ 步的图像 $x_{t-1}$ 乘以一个收缩因子 $\sqrt{1 - \beta_t}$，并加上一个方差为 $\beta_t$ 的高斯噪声得到的。**

该过程一个至关重要的特性是，我们可以直接从初始数据 $x_0$ 以**闭合形式（closed form）** 采样任意时间步 $t$ 的状态 $x_t$，而无需迭代整个马尔可夫链。设 $\alpha_t = 1 - \beta_t$ 且 $\bar{\alpha}_t = \prod_{s=1}^{t} \alpha_s$，则 $x_t$ 在给定 $x_0$ 的条件下的分布为：

$q(x_t|x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t}x_0, (1 - \bar{\alpha}_t)I)$

**公式解释:**
* 这个公式让我们能从原始图像 $x_0$ 一步到位地得到任意时刻 $t$ 的噪声图像 $x_t$ 的分布。
* $\alpha_t = 1 - \beta_t$ 代表了在第 $t$ 步保留的原始信号的比例。
* $\bar{\alpha}_t = \prod_{s=1}^{t} \alpha_s$ 是从第1步到第 $t$ 步的 $\alpha_s$ 的累积乘积，代表了经过 $t$ 步加噪后，原始信号 $x_0$ 还保留的总比例。
* $\sqrt{\bar{\alpha}_t}x_0$ 是分布的均值，表示 $x_t$ 中仍然包含的来自 $x_0$ 的信号成分。
* $(1 - \bar{\alpha}_t)I$ 是分布的协方差，表示 $x_t$ 中所含噪声的总方差。
* **这个公式的重大意义在于，它将一个 $t$ 步的迭代过程，变成了一个单步的计算，极大地提高了训练效率。**

这使得我们可以用一种等价且高效的方式来采样 $x_t$：

$x_t = \sqrt{\bar{\alpha}_t}x_0 + \sqrt{1 - \bar{\alpha}_t}\epsilon$

**公式解释:**
* 这是上述 $q(x_t|x_0)$ 分布的具体采样方程，利用了**重参数化技巧（reparameterization trick）**。
* $x_0$ 是初始的干净图像。
* $\epsilon$ 是从标准正态分布 $\mathcal{N}(0, I)$ 中采样的噪声。
* **该方程清晰地表明：任意时刻 $t$ 的噪声图像 $x_t$，可以看作是原始图像 $x_0$ 和一个随机噪声 $\epsilon$ 的线性组合。** 组合的权重由 $\bar{\alpha}_t$ 控制，$\bar{\alpha}_t$ 随着 $t$ 的增大而减小，意味着信号越来越弱，噪声越来越强。这个技巧是DDPM高效训练的基础。如果噪声时间表 $\beta_t$ 选择得当，最终的潜变量 $x_T$ 将变得与纯各向同性高斯噪声无法区分。

#### 反向过程 (去噪过程)

模型的生成部分是反向过程。这里的目标是学习一个反向的马尔可夫链 $p_\theta(x_{0:T})$，它从纯高斯噪声 $x_T \sim \mathcal{N}(0, I)$ 开始，逐步去噪，最终生成一个与原始数据分布相似的样本。这个反向链中的每一次转移 $p_\theta(x_{t-1} | x_t)$ 也被参数化为一个高斯分布：

$p_\theta(x_{t-1} | x_t) := \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))$

**公式解释:**
* 这个公式描述了反向去噪过程中的单步操作。
* $p_\theta(x_{t-1} | x_t)$ 表示在给定第 $t$ 步的噪声图像 $x_t$ 的条件下，模型预测的第 $t-1$ 步图像 $x_{t-1}$ 的概率分布。
* 这个分布也是一个高斯分布，其均值 $\mu_\theta(x_t, t)$ 和协方差 $\Sigma_\theta(x_t, t)$ 是需要通过神经网络（参数为 $\theta$）学习的。
* **模型的核心任务就是学习一个函数（神经网络），输入当前的噪声图像 $x_t$ 和时间步 $t$，输出去噪后图像的均值和方差。**

#### 训练目标

模型通过优化数据的负对数似然的**变分下界（Variational Lower Bound, ELBO）** 进行训练，这是潜变量模型的标准技术。该目标可以写成一系列KL散度项或熵项在不同时间步上的和。

DDPM论文的一个关键突破是引入了一个简化的训练目标。Ho等人发现，将反向过程的方差 $\Sigma_\theta(x_t, t)$ 固定为与时间相关的常数（例如 $\sigma_t^2 I = \beta_t I$），并将均值 $\mu_\theta(x_t, t)$ 重新参数化为对噪声的预测，可以带来更好的样本质量。具体来说，模型被训练来预测添加到 $x_0$ 中以产生 $x_t$ 的噪声 $\epsilon$。因此，通常是U-Net结构的神经网络被参数化为 $\epsilon_\theta(x_t, t)$，目标函数简化为真实噪声和预测噪声之间的均方误差：

$L_{simple}(\theta) := \mathbb{E}_{t, x_0, \epsilon} \left[ ||\epsilon - \epsilon_\theta(\sqrt{\bar{\alpha}_t}x_0 + \sqrt{1 - \bar{\alpha}_t}\epsilon, t)||^2 \right]$

**公式解释:**
* 这是DDPM最终采用的简化损失函数。
* $\mathbb{E}_{t, x_0, \epsilon}$ 表示对所有时间步 $t$、所有训练数据 $x_0$ 和所有可能的噪声样本 $\epsilon$ 取期望，在实践中就是在一个训练批次上求平均。
* $\epsilon$ 是我们实际添加的真实噪声。
* $\epsilon_\theta(\dots, t)$ 是我们的神经网络模型。它的输入是根据 $x_0$ 和 $\epsilon$ 生成的噪声图像 $x_t = \sqrt{\bar{\alpha}_t}x_0 + \sqrt{1 - \bar{\alpha}_t}\epsilon$ 和当前的时间步 $t$。
* 模型的输出是它对所添加噪声的预测。
* $||\cdot||^2$ 计算了真实噪声和预测噪声之间的L2范数（欧几里得距离）的平方，即均方误差。
* **这个目标的直观含义是：训练一个神经网络，让它在任何噪声水平（由 $t$ 控制）下，都能准确地从噪声图像中预测出被添加的噪声是什么。** 这个目标非常简单且有效，使得训练过程稳定，并能够生成可与GAN媲美的高保真图像。

### 1.2 基于分数的视角与随机微分方程 (SDE)

与DDPM的发展并行，另一条研究路线聚焦于**基于分数的生成模型（Score-Based Generative Modeling）**。这种方法不直接对概率密度 $p(x)$ 建模，而是旨在对其关于数据的梯度 $\nabla_x \log p(x)$ 进行建模，这个量被称为**分数函数（Score Function）**。

#### 分数匹配和朗之万动力学

最初的想法是训练一个神经网络，即分数模型 $s_\theta(x)$，来估计数据分布的分数函数。这可以通过一个名为**分数匹配（Score Matching）** 的目标来实现。一旦学到了准确的分数模型，就可以使用像**退火朗之万动力学（Annealed Langevin Dynamics）** 这样的迭代过程来生成新样本。这是一种采样方法，从随机噪声开始，通过在分数方向（对数密度的梯度方向）上迈出一小步来迭代地更新样本，并在每一步都加入少量噪声以鼓励探索。

这种早期方法的一个重大挑战是，在数据空间的低密度区域，由于缺乏训练样本，分数函数很难被准确估计。为了克服这一点，研究者开发了一种名为**去噪分数匹配（Denoising Score Matching）** 的技术。首先用多种尺度的噪声扰动数据，然后训练分数模型来估计这些含噪数据分布的分数，而不是干净数据的分数。这填充了低密度区域，使得分数估计问题更加适定（well-posed）。

#### SDE 公式化

当Song等人在2021年将用有限数量的噪声水平扰动数据的想法推广到一个由**随机微分方程（SDE）** 控制的连续过程时，一个重大的理论飞跃发生了。该框架考虑了一个连续时间的扩散过程，以时间 $t \in [0, T]$ 为索引，平滑地将复杂的数据分布 $p_0$ 转换为一个简单的、已知的先验分布 $p_T$（例如标准高斯分布）。这个前向过程由一个伊藤（Itô）SDE描述：

$dx = f(x, t)dt + g(t)dw$

**公式解释:**
* 这是一个描述数据如何随时间连续变化的随机微分方程。
* $dx$ 代表数据 $x$ 的无穷小变化。
* $f(x, t)$ 是**漂移系数（Drift Coefficient）**，描述了数据随时间确定性地、朝哪个方向变化的趋势。
* $g(t)$ 是**扩散系数（Diffusion Coefficient）**，控制了随机性（噪声）的强度。
* $dw$ 是一个标准的维纳过程（或布朗运动）的无穷小增量，代表了随机噪声的注入。

这项工作的关键洞见在于，非常奇妙的是，这个前向SDE有一个对应的**逆向时间SDE**，可以将简单先验分布 $p_T$ 中的样本转换回数据分布 $p_0$ 中的样本。这个逆向时间SDE由以下公式给出：

$dx = [f(x, t) - g(t)^2 \nabla_x \log p_t(x)]dt + g(t)d\bar{w}$

**公式解释:**
* 这是能够逆转前向过程的SDE。
* $d\bar{w}$ 是一个逆向时间的维纳过程。
* 最关键的部分是方括号内的项：$[f(x, t) - g(t)^2 \nabla_x \log p_t(x)]$。它表明，逆向过程的漂移项等于前向过程的漂移项减去一个与**分数函数 $\nabla_x \log p_t(x)$** 相关的项。
* **这意味着，如果我们能够在每个时间点 $t$ 估计出被扰动数据 $p_t(x)$ 的分数函数，我们就能精确地知道如何逆转扩散过程。** 通过训练一个与时间相关的神经网络 $s_\theta(x, t)$ 来逼近这个分数函数，我们就可以使用数值SDE求解器来模拟这个逆向时间SDE，从而从噪声中生成新数据。

### 1.3 统一DDPM与分数匹配：SDE框架

SDE框架的引入是一个分水岭，因为它提供了一个统一的数学结构，同时包含了概率性的DDPM公式化和分数匹配方法，揭示了它们是同一枚硬币的两面。这种统一表明，先前工作中使用的离散时间噪声扰动方案，仅仅是离散化连续时间SDE的不同方式。

具体来说，该框架识别出两个关键的SDE，它们对应于先前研究的两大主流：

1.  **方差保持（Variance Preserving, VP）SDE**：该SDE定义为 $dx = -\frac{1}{2}\beta(t)xdt + \sqrt{\beta(t)}dw$，被证明与DDPM的公式化相对应。DDPM中的噪声时间表 $\beta_t$ 是函数 $\beta(t)$ 的一个离散化。该过程在特定条件下会保持数据分布的方差。
2.  **方差爆炸（Variance Exploding, VE）SDE**：该SDE定义为 $dx = \sqrt{\frac{d[\sigma^2(t)]}{dt}}dw$，对应于早期分数匹配与朗之万动力学（SMLD）工作中使用的噪声扰动方案。在这里，噪声尺度 $\sigma(t)$ 随时间增加，导致被扰动数据的方差“爆炸”。

这种统一远不止是理论上的演练；它立即解锁了从离散公式化中不那么明显的新的实用能力。其好处包括：

* **新的采样方法**：通过将生成过程构建为求解逆向时间SDE，任何通用的数值SDE求解器都可以用于采样。这催生了新颖且更高效的采样器，例如**预测-校正（Predictor-Corrector）** 框架。这类采样器首先使用一个数值SDE求解器（“预测器”）来估计下一个状态，然后使用分数模型来校正这个估计（“校正器”），从而提高样本质量。
* **精确的似然计算**：SDE框架允许推导出等价的确定性**常微分方程（ODE）**，称为**概率流ODE（Probability Flow ODE）**。这个ODE与SDE共享相同的边际概率密度 $p_t(x)$，但其确定性的轨迹使得可以使用瞬时变量变换公式精确计算数据的似然。这给了扩散模型一个优于GANs等模型的关键优势，后者通常无法计算似然。
* **有原则的可控生成**：该框架提供了一种有数学依据的方式来执行条件生成并解决广泛的逆问题，如图像修复和上色。这可以通过修改逆向时间SDE来整合条件信息来实现，通常无需重新训练无条件的分数模型。

从特定的算法配方（DDPM, SMLD）转向一个通用的数学框架（SDEs），代表了该领域的显著成熟。它提供了一种更丰富的理论语言，不仅解释了现有方法为何有效，还立即指明了如何构建更好、更灵活、功能更强大的模型。这为后续在采样效率和模型控制方面的许多创新奠定了基础。

## 第二部分：追求效率——加速生成

尽管基础模型展示了卓越的生成质量，但它们共同存在一个重大的实践缺陷：采样过程极其缓慢。最初的DDPM公式需要数千次顺序的去噪步骤——每一步都涉及对一个大型神经网络的完整前向传播——才能生成单张图像。这种计算负担使它们比GANs等单步模型慢了几个数量级，并阻碍了它们在实时或大规模应用中的使用。这种低效率为研究创造了强大的动力，开启了一个专注于加速生成的激烈且自我强化的循环。这个“效率飞轮”经历了不同的阶段，从巧妙的算法变通开始，发展到更具原则性的数值优化，并最终在模型层面达到了根本性改变生成过程的解决方案。

### 2.1 通过确定性过程加速采样 (DDIM)

在加速扩散模型采样方面的第一个重大突破来自Song、Meng和Ermon在2021年提出的“去噪扩散隐式模型”（DDIM）。DDIM的关键创新在于推广了前向扩散过程，从DDPM严格的马尔可夫链转向了一类更灵活的非马尔可夫过程。

作者们观察到，简化的DDPM训练目标仅依赖于边际分布 $q(x_t|x_0)$，而不依赖于潜变量的完整联合分布 $q(x_{1:T}|x_0)$。这一洞见意味着许多不同的前向过程都可以导出完全相同的训练目标。DDIM利用这种灵活性来定义一个全新的推断过程家族。

这种非马尔可夫公式化带来了两个深远的影响。首先，它允许一个**完全确定性**的生成过程。通过将一个随机性参数 $\eta$ 设为0（$\eta=1$ 对应于DDPM过程），生成更新步骤中的随机噪声项便会消失。在这种确定性模式下，同一个初始噪声向量 $x_T$ 将总是映射到完全相同的输出图像 $x_0$，这一特性也使得在潜空间中对图像进行有意义的语义插值成为可能。

其次，也是对效率最重要的一点，DDIM框架允许使用原始 $T$ 个时间步的一个**更短的“子序列”**进行采样。用户无需执行全部 $T$（例如1000）个步骤，而是可以选择一个较小的步数 $S$（例如20-100），并通过仅迭代这个子序列来生成样本。这使得在仅有轻微样本质量下降的情况下，获得了惊人的10-50倍的墙钟时间加速。至关重要的是，这种加速**无需任何重新训练**。一个预训练好的DDPM模型可以直接与DDIM采样过程配合使用，使其成为一个高度实用且能立即解决速度问题的方案。DDIM是效率追求中第一个“低垂的果实”，它提供了一个巧妙的算法技巧，显著提高了扩散模型的可用性。

### 2.2 ODE求解器与先进采样方案的兴起

尽管DDIM提供了显著的加速，但与连续时间SDE及其对应的概率流ODE（如第一部分所述）的联系，为基于数十年来数值分析研究的、更具原则性且更快的采样方法打开了大门。研究人员不再仅仅是在离散链中跳过步骤，而是开始将采样视为一个更高效地求解概率流ODE的问题。

这催生了各种先进ODE求解器的开发和应用，这些求解器比DDPM中隐式使用的简单欧拉法更精确。像 **DPM-Solver** 及其后续版本 **DPM-Solver++** 这样的高阶求解器是专为扩散模型设计的。这些方法利用先前步骤的信息来对当前步骤做出更准确的预测，使它们能够采取更大的步长而不会累积显著误差。因此，它们可以在少至10-20次函数评估（NFE）中生成非常高质量的样本，这与DDIM通常需要数百步才能获得好结果相比是一个巨大的进步。从这一研究路线中涌现的其他流行且高效的求解器还包括 **UniPC**（统一预测-校正器），它同样能在5-10步内取得优异结果。

另一条并行的研究路线不关注改变求解器本身，而是着力于优化**采样时间表**——即生成过程中使用的特定时间步序列 $\{t_i\}_{i=1}^S$。研究发现，相比于使用均匀或线性间隔的时间步，某些特定的时间表可以在相同步数下产生更好的结果。一些方法提出将学习最优时间表构建为一个动态规划问题，以找到在给定NFE预算下能最大化ELBO的步骤序列。2024年更新的研究则聚焦于将采样步骤与模型的训练分布对齐。在实时应用领域，像 **StreamDiffusion** 这样的专用流水线使用新颖的调度技术，如批处理步骤和缓存特征，以在标准消费级硬件上实现交互式实时生成。这些基于求解器和时间表的方**法代表了效率驱动的第二阶段，超越了DDIM的跳步，转而利用更基本的数值优化原理。

### 2.3 蒸馏范式：压缩去噪路径

解决缓慢迭代采样过程的终极方案是完全消除它。这引出了效率研究的第三个也是最新的阶段：**知识蒸馏**。其核心思想是将一个大型、预训练的“教师”扩散模型的多步推理过程，压缩到一个更小、更快的“学生”模型中，该模型能够在一个或极少数几个步骤内生成图像。

最早成功的尝试之一是Salimans和Ho在2022年提出的**渐进式蒸馏（Progressive Distillation）**。在这种方法中，一个学生模型被训练来用一次跳跃完成教师模型采样链中的两个步骤。学生的权重从教师模型初始化，并在由教师生成的样本对 $(x_t, x_{t-2})$ 上进行训练。一旦训练完成，这个学生就成为新的教师，该过程可以重复进行。每一轮蒸馏都有效地将所需的采样步数减半。

一个更直接的方法由Song等人在2023年通过**一致性模型（Consistency Models）** 引入。这类模型被训练来将给定概率流ODE轨迹上的任意点 $(x_t, t)$ 直接映射到轨迹的原点，即干净图像 $x_0$。因为模型的输出对于同一轨迹上的所有点都是一致的，所以原则上它可以通过将纯噪声 $x_T$ 直接映射到最终图像来实现单步生成。一致性模型可以通过两种方式训练：从预训练的扩散模型中蒸馏知识（一致性蒸馏），或者从头开始训练它们（一致性训练）。

这个一致性框架被证明极其强大，特别是当应用于像Stable Diffusion这样的潜在扩散模型时。这催生了**潜在一致性模型（Latent Consistency Models, LCMs）** 的发展。LCMs通过蒸馏一个大型预训练的潜在扩散模型而创建，使其能够在短短1-4步内生成高质量图像。一个尤其有影响力的创新是 **LCM-LoRA**，它将一致性蒸馏的目标仅应用于一小组LoRA适配器权重。这允许用户创建一个微小的（几MB）“加速模块”，该模块可以插入到任何基础模型（如Stable Diffusion）的微调版本中，以实现极快的采样，而无需蒸馏整个数十亿参数的模型。

2024年和2025年的研究继续完善这一蒸馏范式。像**分布匹配蒸馏（Distribution Matching Distillation）** 和 **EM蒸馏（EMD）** 等方法提出了更复杂的物镜，旨在更好地匹配教师模型的边际分布，从而在像ImageNet这样的挑战性基准上以及像Stable Diffusion这样的文生图模型上，为单步生成带来了最先进的结果。这种模型层面的压缩代表了效率飞轮的成熟，从根本上改变了模型自身，使其天生就具备快速性。

## 第三部分：新轨迹——基于流的生成模型

在一条主要的研究分支致力于让扩散模型的迭代去噪过程变得更快的同时，一个并行的演进轨迹出现了，它从第一性原理出发重新思考了生成过程。这类模型不学习如何逆转一个加噪过程，而是旨在学习一个直接的、连续的变换——一个“流”——从一个简单的先验分布（例如高斯噪声）到复杂的数据分布。这种从“去噪”到“传输”的概念性转变，催生了一类全新、强大且高效的生成模型。

### 3.1 流匹配：一种无需模拟的训练方法

这条新轨迹的基础是**连续归一化流（Continuous Normalizing Flows, CNFs）** 的概念。CNF通过定义一个速度向量场 $v_t(x)$ 来对复杂分布进行建模，该向量场的演化由一个常微分方程（ODE）控制。模拟这个ODE可以将简单基础分布中的样本转换为目标分布中的样本。虽然功能强大，但早期CNFs的训练是出了名的困难和计算昂贵，通常需要通过ODE求解器进行反向传播。

**流匹配（Flow Matching, FM）**，由Lipman等人在2023年引入，提出了一种革命性的、无需模拟的CNF训练方法。其核心思想是定义一个目标概率路径 $p_t(x)$ 和一个相应的向量场 $u_t(x)$，该向量场将噪声分布 $p_0$ 传输到数据分布 $p_1$。然后，一个神经网络模型 $v_\theta(x,t)$ 被训练来匹配这个目标向量场，通过最小化一个简单的回归损失：

$\mathbb{E}_{t, p_t(x)}[||v_\theta(x,t) - u_t(x)||^2]$

**公式解释:**
* 这是流匹配的理论目标函数。
* $\mathbb{E}_{t, p_t(x)}$ 表示对所有时间 $t$ 和在时刻 $t$ 的概率路径 $p_t(x)$ 上的所有点 $x$ 取期望。
* $u_t(x)$ 是我们想要学习的“真实”速度场。
* $v_\theta(x,t)$ 是我们的神经网络，它试图在任何时间 $t$ 和位置 $x$ 预测出这个速度。
* 这个损失函数的目标是让神经网络预测的速度 $v_\theta$ 与真实的速度 $u_t$ 尽可能接近。

主要挑战在于，边际路径 $p_t(x)$ 及其向量场 $u_t(x)$ 通常是难以计算的。使流匹配变得实用的关键技巧是**条件流匹配（Conditional Flow Matching, CFM）**。CFM不定义难以处理的边际路径，而是定义一个简单的条件概率路径族 $p_t(x|x_1)$，它连接一个噪声样本和一个数据样本 $x_1$。例如，一个简单的路径可以是噪声点 $x_0$ 和数据点 $x_1$ 之间的直线插值。相应的条件向量场 $u_t(x|x_1)$ 也是简单且可计算的。然后，CFM的目标是让模型的向量场与这些简单的条件向量场进行回归：

$\mathbb{E}_{t, q(x_1), p_t(x|x_1)}[||v_\theta(x,t) - u_t(x|x_1)||^2]$

**公式解释:**
* 这是流匹配在实践中使用的目标函数。
* $\mathbb{E}_{t, q(x_1), p_t(x|x_1)}$ 表示对所有时间 $t$、所有数据点 $x_1$（从真实数据分布 $q(x_1)$ 中采样）以及连接噪声和该数据点的条件路径 $p_t(x|x_1)$ 上的所有点 $x$ 取期望。
* $u_t(x|x_1)$ 是连接单个噪声点和单个数据点 $x_1$ 的、简单且易于计算的“局部”速度场。
* **CFM的绝妙之处在于，通过最小化模型与这些简单的、逐样本的条件速度场之间的差距，模型最终能学习到正确的、难以计算的全局边际速度场。**

论文非凡地证明了，这个简单的、可计算的CFM目标的期望梯度，与那个难以计算的边际FM目标的梯度是完全相同的。这使得模型只需观察简单的、逐样本的路径就能学习到正确的边际向量场。

FM框架具有高度的通用性。研究表明，来自扩散模型的概率流ODE只是可以使用的路径中的一个特例。在扩散路径上使用FM进行训练，甚至可以比传统的基于分数匹配的目标更稳定。更重要的是，FM为使用其他更高效的路径打开了大门。论文中引入的一个关键例子是源自**最优传输（Optimal Transport, OT）** 的路径，它对应于噪声点和数据点之间的直线轨迹。这些路径比扩散的弯曲路径更简单、更直接，经验证明它们能带来更快的训练、更快的采样和更好的整体性能。

### 3.2 矫正流：拉直路径以实现单步生成

**矫正流（Rectified Flow）**，由Liu等人同期提出，是一个具体且高效的公式化方法，可以看作是流匹配的一个实例。它明确地专注于学习一个遵循连接两个分布——$\pi_0$（噪声）和 $\pi_1$（数据）——的点的**直线路径**的ODE模型。模型被训练来匹配这些线性插值的向量场。

矫正流最关键的创新是 **“重流”（reflow）** 程序。在训练好一个初始模型（称为1-矫正流）后，可以用它通过模拟其学习到的ODE来生成成对的噪声和数据 $(z_0, z_1)$。然后，一个新模型（2-矫正流）在这些自举生成的配对上进行训练。作者证明，这个重流过程产生了一个具有可证明的**更直轨迹**的新ODE。

寻求更直路径的动机是深远的。一个描述完美直线轨迹的ODE，可以用单个欧拉离散化步骤以零误差求解。因此，**重流程序是一种将模型推向成为完美单步生成器的机制。** 虽然初始的1-矫正流在少量采样步骤下已表现良好，但2-矫正流仅用一到两步就能达到高质量的结果，大大优于标准的扩散方法。2024年的研究进一步增强了这一过程，表明通过改进的训练技术——例如在训练期间使用U形的时间步分布和基于LPIPS的损失函数——单个重流阶段就足以实现最先进的少步生成性能，其效果可与知识蒸馏方法相媲美甚至超越。这种直接的路径拉直方法从一个与第二部分讨论的方法完全不同的角度解决了核心的效率挑战。这一范式的成功，通过其在像Stable Diffusion 3这样的顶尖模型中的采用得到了印证，后者结合了矫正流框架和Transformer架构。

### 3.3 框架比较：扩散 vs. 流匹配

流匹配和矫正流的出现代表了生成模型领域一次重大的概念性转变。扩散模型从根本上是关于**去噪**，而基于流的模型则是关于**传输**。

* 在一个基于DDPM或SDE的模型中，神经网络被训练来预测在给定时间 $t$ 被扰动数据的某个属性——要么是添加的噪声 $\epsilon$，要么是分数 $\nabla \log p_t(x)$。从噪声到数据的路径是一个**涌现属性（emergent property）**，它源于迭代地应用这个学习到的去噪函数。模型从未显式地推理过完整的轨迹。
* 相反，在一个基于流匹配或矫正流的模型中，神经网络被训练来直接学习定义传输路径本身的速度向量 $v(x,t)$。路径不是一个涌现属性；它作为训练目标的一部分被**显式定义**（例如，定义为一条直线），模型则学习去遵循它。

这种概念上的差异带来了切实的实践后果。基于流的模型在训练期间是“无模拟”的，因为它们只需要在预定义的路径上采样点，这可以更稳定和高效。此外，它们对直线路径的天然亲和力（通过OT或重流程序）使它们天生就非常适合少步或单步生成，直接解决了原始扩散范式的核心效率挑战。这些基于流的方法在2022年至2024年间的迅速崛起和被采用，表明该领域并不仅仅满足于优化去噪框架，而是在积极寻求更直接、更优雅且可能更高效的生成原理。

**表2：基础生成框架对比**
| 框架 | 核心机制 | 训练目标 | 关键创新 | 主要优势 |
| :--- | :--- | :--- | :--- | :--- |
| **DDPM/SDE** | 学习逆转一个固定的加噪过程（离散或连续）。 | 去噪分数匹配 / ELBO最大化。 | 统一了离散和连续视角；实现了有原则的采样。 | 样本质量高，理论可追溯。 |
| **DDIM** | 将前向过程推广为非马尔可夫过程。 | 与DDPM相同。 | 允许确定性路径和跳过采样步骤。 | 无需重训练即可实现更快的采样（约10-50倍）。 |
| **流匹配** | 学习一个将噪声分布传输到数据分布的向量场。 | 将模型向量场与目标向量场进行回归（CFM）。 | 连续归一化流的无模拟训练。 | 灵活选择路径（如OT），训练更快。 |
| **矫正流** | 流匹配的一个实例，学习遵循直线路径。 | 与流匹配相同，使用线性插值路径。 | “重流”程序迭代地拉直路径。 | 在少步和单步生成中表现出色。 |

## 第四部分：架构演进——从U-Net到Transformer

前述部分描述的生成框架由大型神经网络驱动，这些网络执行着预测噪声或速度的核心任务。这些底层架构的演进，对于扩散模型的故事来说，与框架本身的演进同等重要。一个关键的趋势是生成式视觉的“LLM化”：一种战略性的转变，从具有强烈图像特定归纳偏置的架构（如CNNs），转向更通用、可大规模扩展的Transformer架构。这一转变不仅仅是架构的替换，更是一种哲学上的变革，它优先考虑**可扩展性（scalability）**，从而实现了在当今最大模型中看到的性能可预测性增长和涌现能力。

### 4.1 U-Net主干及其在早期模型中的作用

第一波高性能扩散模型，包括最初的DDPM和Stable Diffusion 1.x/2.x，其主力架构是**U-Net**。U-Net最初为生物医学图像分割而开发，其结构被证明非常适合去噪任务。

其架构包括三个主要部分：一个收缩路径（编码器）、一个中心瓶颈和一个对称的扩展路径（解码器），这使其具有标志性的U形结构。编码器是一个典型的卷积网络，它逐步对输入图像进行下采样，在每一层增加特征通道的数量，以捕捉越来越抽象、高层次的信息。解码器则对这些信息进行上采样，逐步重建出高分辨率的输出。

U-Net对于此任务最重要的特性是其**跳跃连接（skip connections）** 的使用。这些连接将高分辨率的特征图直接从编码器传递到解码器中对应的层，并与上采样的特征进行拼接。这使得网络能够将来自瓶颈的高层语义信息与来自编码器的低层空间细节相结合，这对于在最终生成的图像中重建精细的纹理和清晰的边缘至关重要。

条件被整合到U-Net的多个点。**时间条件**通过将时间步 $t$ 转换为一个正弦位置编码，然后通过一个小MLP处理并注入到整个U-Net的残差块（ResBlocks）中来处理。

**类别或文本条件**（例如，来自CLIP文本编码器）通常通过插入到U-Net块中的**交叉注意力（cross-attention）** 层来整合。图像特征作为查询（Query），而文本嵌入作为键（Key）和值（Value），这使得模型能够将去噪过程与提供的提示对齐。

### 4.2 Transformer革命：DiT及其缩放法则

尽管U-Net非常有效，但其卷积性质并未展现出与Transformer在自然语言处理（NLP）领域凭借大型语言模型（LLMs）掀起革命时相同的可预测缩放特性。这一观察启发了Peebles和Xie在2023年初开发的**扩散Transformer（Diffusion Transformers, DiT）**，这是一篇里程碑式的论文，它用一个标准的Transformer架构完全取代了U-Net主干。

其核心架构思想是将图像去噪任务重塑为一个**序列处理问题**。模型不直接在像素上操作。相反，输入的潜在图像首先被分解成一系列不重叠的**潜在块（latent patches）**，这与视觉Transformer（ViT）中的分块机制类似。这些块，连同条件信息（时间步和类别嵌入），作为“令牌”（tokens）被送入Transformer。然后，Transformer处理这个序列，并输出一个去噪后的潜在块序列，这些块最终被重新组装成最终的潜在图像。

DiT论文最关键的发现是，这些模型展现出清晰且可预测的**缩放法则（Scaling Laws）**。随着模型大小（深度/宽度）或训练计算量的增加，生成质量（以Fréchet Inception Distance, FID衡量）以一种可预测的幂律方式提高。这是该领域期待已久的“绿灯”。它证实了从扩展LLMs中得到的经验教训可以直接应用于生成式视觉模型，从而为投资大量计算资源来训练更大、能力更强的模型提供了正当理由。

这种“扩展优先”的哲学在OpenAI于2024年发布的顶尖视频生成模型**Sora**中得到了完美体现。Sora的架构就是一个扩展版的扩散Transformer。它将DiT的概念扩展到视频领域，通过处理**时空潜在块（spacetime latent patches）** 来运作。它首先将输入视频压缩到一个紧凑的潜在表示中，然后提取一个同时捕捉空间（图像平面）和时间信息的块序列。这使得单个Transformer架构能够统一地对场景的视觉外观及其时间演变进行建模，从而带来了前所未有的时间一致性和生成质量。

### 4.3 多模态扩散Transformer (MMDiT) 与 Stable Diffusion 3

最新一代的旗舰开源模型，如Stable Diffusion 3（SD3），进一步改进了DiT架构，以更好地处理多模态条件。SD3引入了**多模态扩散Transformer（Multimodal Diffusion Transformer, MMDiT）**，它建立在DiT概念之上，但为处理文本和图像输入做出了关键性修改。

MMDiT的核心创新在于其**融合两种模态的方式**。认识到图像和文本嵌入具有根本不同的结构，MMDiT使用两组独立的权重来分别处理图像块令牌和文本提示令牌。然而，在经过这个初始的模态特定处理之后，两个令牌序列被拼接在一起，并送入一个**单一、统一的注意力机制**。这种“两套权重，一套注意力”的方法，使得两种表示可以在各自的空间中被处理，同时仍然能在注意力层内实现它们之间深度的交互和影响。这种设计被证明能极大地改善对精细提示的遵循能力，并且，值得注意的是，它还能在生成的图像中准确地渲染文本和排版——这是扩散模型长期以来的一个挑战。

此外，SD3采用了由三个不同文本编码器（两个不同大小的CLIP模型和一个大型T5模型）组成的套件，来创建文本提示的丰富而鲁棒的表示。这为模型提供了多样的语义信息，并为用户提供了灵活性，因为最大的T5编码器可以在推理时被省略，以在轻微性能损失的情况下降低内存需求。MMDiT架构与矫正流框架（来自第三部分）的结合，使SD3成为了一个展示架构与框架创新如何融合的有力范例。

从U-Net到DiT再到MMDiT的演进是一条清晰的叙事线。该领域从一个专门的图像架构（U-Net）转向一个通用的、可扩展的序列处理器（DiT），以解锁类似LLM的扩展能力。最新的步骤（MMDiT）则改进了这个序列处理器，使其能更智能地处理文本和图像块的“多模态语言”。这种由追求可扩展性驱动的架构演进，是当今最大模型中看到的如世界模拟等涌现能力的主要推动者。

**表3：扩散模型架构的演进**
| 架构 | 核心组件 | 条件化方法 | 关键优势 | 旗舰模型 |
| :--- | :--- | :--- | :--- | :--- |
| **U-Net** | CNN编码器/解码器, ResBlocks, 跳跃连接 | 时间嵌入在ResBlocks中添加；文本/类别通过交叉注意力。 | 强大的图像特定归纳偏置；在保持空间细节方面表现出色。 | Stable Diffusion 1.x/2.x, Midjourney v1-v4 |
| **DiT** | 标准Transformer，操作于潜在块上 | 条件令牌（时间、类别）前置于序列。 | 展现出可预测的缩放法则，能通过更多计算获得巨大性能提升。 | OpenAI's Sora |
| **MMDiT** | DiT，对图像和文本令牌有独立权重，但共享注意力。 | 文本和图像令牌用独立权重处理，然后拼接进行注意力计算。 | 显著改善了多模态融合，带来更好的提示遵循和排版能力。 | Stable Diffusion 3 |

## 第五部分：获得控制权——微调与条件生成

尽管基础框架和架构提供了强大的生成能力，但它们的原始输出通常是不受约束的。为了将这些模型转变为实用且可操控的创意工具，一个围绕条件生成和高效微调的丰富技术生态系统应运而生。这一演进展现出一种清晰的**模块化**趋势。社区没有构建庞大、单一用途的模型，而是拥抱了一种“平台+插件”的范式。一个训练成本高昂的大型基础模型作为平台，而像ControlNets和LoRAs这样更轻量级的、任务特定的模块则充当“乐高积木”，可以被添加、移除和组合，以实现创意成果的组合爆炸。这种方法使定制大众化，使其在无需超级计算资源的情况下成为可能。

### 5.1 基础引导技术

最早的控制生成方法聚焦于在推理时引导一个预训练模型的采样过程。

* **分类器引导（Classifier Guidance）**：这种最初由Dhariwal和Nichol在2021年提出的方法，使用一个独立的、预训练的图像分类器来引导扩散过程。在每个去噪步骤中，计算分类器对当前噪声图像 $x_t$ 的对数概率的梯度。这个梯度 $\nabla_{x_t} \log p_\phi(y|x_t)$ 指示了如何扰动 $x_t$ 以使其更像目标类别 $y$。然后将此梯度添加到反向过程的均值中，从而将生成推向期望的类别。尽管在提高样本保真度和类别一致性方面有效，但此方法需要训练和维护一个额外的分类器，并且仅限于该分类器所知的类别。

* **无分类器引导（Classifier-Free Guidance, CFG）**：一个更优雅、更强大的解决方案，由Ho和Salimans在2022年引入，并迅速成为高质量条件生成的行业标准。CFG通过修改扩散模型自身的训练过程，**消除了对独立分类器的需求**。它训练一个单一的条件扩散模型 $\epsilon_\theta(x_t, t, c)$，使其能够接收某些上下文 $c$（例如，类别标签或文本提示）作为条件。在训练期间，这个条件 $c$ 以一定的固定概率（例如10-20%）被随机替换为一个特殊的**空令牌 $\emptyset$**。这迫使单个模型同时学习条件下的预测 $\epsilon_\theta(x_t, t, c)$ 和无条件下的预测 $\epsilon_\theta(x_t, t, \emptyset)$。

在推理时，模型会同时计算这两个预测。最终的噪声预测是从无条件预测出发，朝向条件预测方向进行的一次外插：

$\hat{\epsilon}_\theta(x_t, t, c) = \epsilon_\theta(x_t, t, \emptyset) + w \cdot (\epsilon_\theta(x_t, t, c) - \epsilon_\theta(x_t, t, \emptyset))$

**公式解释:**
* 这是CFG的核心方程。
* $\epsilon_\theta(x_t, t, \emptyset)$ 是模型在**无条件**（即忽略提示）下预测的噪声。
* $\epsilon_\theta(x_t, t, c)$ 是模型在**有条件**（即遵循提示 $c$）下预测的噪声。
* $(\epsilon_\theta(x_t, t, c) - \epsilon_\theta(x_t, t, \emptyset))$ 是一个向量，代表了从“无方向”到“有方向”的变化方向。
* $w$ 是**引导尺度（guidance scale）**，一个用户可以控制的超参数。
* **整个公式的含义是：最终用于去噪的噪声方向，是在无条件预测的基础上，沿着“条件方向”向量进行加强。** 当 $w > 1$ 时，模型被强制生成更忠实于条件 $c$ 的样本，通常以牺牲一些多样性为代价来换取更高的提示遵循度。这个简单的技巧非常有效，几乎是所有现代文生图模型的标配。

### 5.2 架构级控制：ControlNet框架

虽然CFG提供了强大的语义控制，但它无法提供精细的**空间控制**。用户无法轻易地指示模型遵循特定的边缘图、人体姿态或深度图。这个限制被Zhang等人在2023年引入的**ControlNet**这一架构级修改巧妙地解决了。

ControlNet的核心思想是为一个大型、预训练的扩散模型（如Stable Diffusion）增加一个额外的、可训练的输入流，用于接收空间条件。为了在不损害强大的、数十亿参数的预训练模型的前提下做到这一点，ControlNet创建了U-Net编码器块的一个**可训练副本**。原始大型模型的权重被完全冻结，在训练期间不进行任何更新。

输入条件（例如，Canny边缘图）首先被一个小编码器处理，然后送入这个可训练的副本。这个可训练副本的输出，随后被送回原始U-Net的**冻结解码器块**中。可训练部分和冻结部分之间的连接是通过特殊的**“零卷积”**层实现的。这些是简单的1x1卷积层，其权重和偏置都被初始化为零。

这些零卷积的作用至关重要。通过从零权重开始，它们确保在微调之初，可训练副本不会向强大的、冻结的主干网络添加任何信息（因此也不会添加有害的噪声）。控制信号随着零卷积的权重在训练过程中从零开始增长而逐渐、平稳地学习。这种优雅的设计避免了直接微调大型模型时可能发生的灾难性遗忘，并使得ControlNet即使在相对较小的数据集（<5万张图像）上也能稳健地训练。ControlNet实现了大量的空间控制，包括边缘、人体姿态、深度图、分割图和用户涂鸦，使其成为艺术家和设计师不可或缺的工具。2024-2025年的最新扩展，如**DC-ControlNet**，正在探索通过解耦场景中不同元素的条件来实现更灵活的控制。

### 5.3 参数高效微调 (PEFT)：LoRA的角色

虽然ControlNet提供了空间控制，但用户通常希望定制模型的**风格**或教它一个**新概念**，比如某个特定人物的面孔。为每个新概念都对一个数十亿参数的模型进行完整微调，在计算上和经济上都是不现实的。这一需求催生了**参数高效微调（Parameter-Efficient Fine-Tuning, PEFT）** 方法，其中**低秩适应（Low-Rank Adaptation, LoRA）** 最为突出。

LoRA由Hu等人在2021年为LLMs引入，其基础假设是模型在适应新任务时，其权重的变化具有一个低的“内在秩”。LoRA不更新模型层（例如，注意力层）的整个、巨大的权重矩阵 $W$，而是**冻结 $W$**，并学习权重更新量 $\Delta W$ 的一个低秩分解。这是通过训练两个小得多的矩阵 $B$ 和 $A$ 来实现的，使得 $\Delta W = B \cdot A$，其中秩 $r$ 是一个小的超参数（例如4到128）。修改后的前向传播变为：

$h = Wx + \alpha(BA)x$

**公式解释:**
* $W$ 是原始的、被冻结的大权重矩阵，$x$ 是输入。$Wx$ 是原始模型的计算部分。
* 我们不直接更新 $W$，而是学习一个“旁路”更新 $(BA)x$。
* $A$ 和 $B$ 是两个小得多的矩阵，它们的乘积 $BA$ 是一个与 $W$ 同样大小的矩阵，但其“秩”很低（由中间维度 $r$ 控制）。这个低秩矩阵 $BA$ 就是对原始权重 $W$ 的增量更新 $\Delta W$ 的近似。
* $\alpha$ 是一个缩放因子，用于控制这个更新的强度。
* **这个技术的精髓在于，我们只需要训练和存储非常小的矩阵 $A$ 和 $B$，而不是巨大的 $W$。**

这项技术非常适合扩散模型。通过将LoRA应用于U-Net的交叉注意力层，用户可以在仅仅几十张（例如5-10张）特定主题或风格的图像上微调像Stable Diffusion这样的巨型模型。训练得到的LoRA矩阵非常小（通常只有几MB），与数GB的基础模型形成鲜明对比。这使得用户可以实际地训练、存储和分享数百个“概念”LoRA，这些LoRA可以在推理时动态加载和组合。像Civitai这样的平台上的社区是这种模块化范式成功的证明，用户们分享了成千上万个用于角色、艺术风格、服装等的LoRA。

2024-2025年的最新研究继续在这一强大思想的基础上发展，探索了在没有概念混淆的情况下组合多个LoRA的方法（**LoRA-Composer**）、在不同基础模型之间迁移LoRA适配器的方法（**LoRA-X**）、使用引导来提高LoRA生成多样性的方法（**AutoLoRA**），甚至训练超网络来根据用户输入即时生成LoRA权重。

### 5.4 提升稳定性与质量的先进训练策略

除了引导和微调之外，研究人员还识别并解决了标准训练目标本身存在的一些根本性问题，以提高收敛速度和最终模型质量。

标准的扩散训练目标平等地对待每个时间步 $t$ 的去噪任务。然而，对训练动态的分析揭示，不同时间步的梯度可能会相互冲突。去噪一个轻微扰动的图像（低噪声，接近 $t=0$）与去噪一个几乎是纯噪声的图像（高噪声，接近 $t=T$）是截然不同的任务。为一个任务进行优化可能会损害在另一个任务上的表现。

为了解决这个问题，Hang等人在2023年提出的**最小信噪比加权策略（Min-SNR Weighting Strategy）**，将扩散训练重塑为一个多任务学习问题，其中每个时间步都是一个独立的“任务”。该策略建议根据每个训练步骤的**信噪比（Signal-to-Noise Ratio, SNR）** 来加权其损失，SNR定义为 $\text{SNR}(t) = \bar{\alpha}_t / (1 - \bar{\alpha}_t)$。其关键思想是**降低**那些SNR非常低（即最嘈杂的样本）的时间步的损失权重，因为在这些时间步，模型的预测基本上是猜测，训练信号不可靠。建议的损失权重为 $\lambda_t = \min(\text{SNR}(t), \gamma)$，其中 $\gamma$ 是一个固定的超参数（例如5）。这个简单的重加权方案有效地平衡了不同时间步的贡献，减少了冲突的梯度，并带来了显著更快的收敛速度（高达3.4倍）和更好的最终FID分数。

Lin等人在2024年的进一步分析发现了一个常见的实现中的另一个微妙缺陷：大多数噪声时间表没有强制执行**零终端信噪比（Zero Terminal SNR）**。这意味着即使在最终时间步 $T$，潜变量 $x_T$ 仍然包含来自原始图像 $x_0$ 的微弱信号。这与推理过程产生了不一致，因为推理总是从零信号的纯高斯噪声开始。该论文提出了一个简单的修复方法：重新缩放噪声时间表以确保 $\bar{\alpha}_T=0$（从而 $\text{SNR}(T)=0$），并调整CFG缩放以防止模型在这个新的边界条件下生成过曝的图像。更先进的框架，如**FullDiffusion (2024)**，旨在通过修改噪声预测器和SDE求解器使其在整个时间区间 $(-\infty, \infty)$ 内保持稳定，从而消除任何时间截断启发式方法的需求。这些先进策略表明，对扩散训练微妙动态的理解正在成熟，从而催生出更稳健、更高效的模型。

## 第六部分：拓展画布——多模态与科学前沿 (2024-2025)

在2D图像生成领域磨练出的原理和技术，已成为攻克日益增多的数据模态的强大跳板。扩散模型成功扩展到视频、音频和3D等新领域，并非简单地将同一算法应用于各处。相反，它持续揭示了**“架构-表示-数据”**三位一体协同设计的重要性。任何给定模态的突破，通常都需要在以下三方面实现协同创新：（1）一个能够处理该数据结构的可扩展**架构**（越来越多地是Transformer），（2）一个使问题变得易于处理的合适**表示**（例如，视频的时空块或音频的压缩潜变量），以及（3）一个用于学习的、海量的相关**数据**集。本节将探索这些新前沿的最新技术，重点关注2024年和2025年的突破。

**表4：多模态应用展示 (2024-2025)**
| 领域 | 旗舰模型 | 关键架构/表示创新 | 顶尖能力 |
| :--- | :--- | :--- | :--- |
| **视频** | OpenAI's Sora | 在时空潜在块上扩展的扩散Transformer (DiT)。 | 生成长达一分钟、时间上连贯且具有涌现物理特性的视频。 |
| **音频** | Stability AI's Stable Audio 2.0 | 在高度压缩的VAE潜变量上使用DiT。 | 生成3分钟长、结构化的立体声音乐曲目。 |
| **3D生成** | DiffGS | 在连续的“高斯泼溅函数”上进行扩散，而非离散点。 | 生成高质量、非结构化的高斯泼溅表示。 |
| **蛋白质设计** | FrameDiff / TaxDiff | 在骨架上进行SE(3)等变扩散 / 具有分类学引导的可控序列生成。 | 生成新颖、可设计的蛋白质骨架或可控的蛋白质序列。 |
| **材料科学** | MatterGen | 针对材料属性微调并使用无分类器引导的扩散模型。 | 基于期望属性，逆向设计新颖、稳定的晶体结构。 |

### 6.1 视频生成：用Sora模拟世界

生成视频提出了一个巨大的挑战，它不仅要求每一帧都具有高视觉质量，还要求在时间上具有连贯和逻辑上的一致性。OpenAI于2024年初发布的**Sora**，代表了该领域的巨大飞跃。

其核心，Sora是扩散Transformer（DiT）发现的缩放法则的直接应用。其架构是一个被大规模扩展的DiT。关键创新在于其**数据表示**。Sora在**时空潜在块**上操作。它首先使用一个强大的视频压缩网络，将原始视频映射到一个在空间和时间上都被压缩的低维潜在空间。然后，这个潜在视频被分解成一系列的块，每个块都封装了一个空间区域和一段时间。这些时空块成为DiT的“令牌”，使得单个Transformer模型能够以统一的方式对场景的外观和运动进行推理和生成。

这种方法最深远的影响是**世界模拟**能力的涌现。通过在一个庞大而多样化的视频数据集上训练这种可扩展架构，Sora在没有被明确编程的情况下，学习到了一个物理世界的隐式模型。它展示了对3D一致性（当相机移动时物体保持其形状）、长程连贯性和物体持久性（即使被遮挡，物体仍然存在）的非凡理解。它可以模拟复杂的互动，如角色留下脚印或水面泛起涟漪。这表明，扩展视频生成模型是开发通用物理和数字世界模拟器的一条有前途的路径。

### 6.2 音频合成：用Stable Audio 2.0创作连贯的长篇音乐

与视频类似，生成长篇、具有音乐连贯性的音频也很困难。模型不仅必须捕捉局部纹理（音色、音符），还必须捕捉大规模结构，如引子、主歌和副歌，这些结构可以跨越数分钟。

Stability AI于2024年发布的**Stable Audio 2.0**，使用一种反映了其他大规模生成模型关键原则的架构来应对这一挑战。它有效地运用了“架构-表示-数据”三位一体。

* **表示**：它使用一个新的、高度压缩的变分自编码器（VAE），将原始音频波形转换为一个更短、更紧凑的潜在表示。这种压缩是使长序列音频数据变得易于管理的关键。
* **架构**：与前代产品使用的U-Net不同，Stable Audio 2.0采用扩散Transformer（DiT）作为其主干。与视频一样，Transformer架构更适合于对完整音乐曲目的潜在序列中存在的长程依赖性进行建模。
* **数据**：该模型完全在来自AudioSparx音乐库的授权数据集上进行训练，确保了对创作者的公平补偿，并为学习提供了高质量、结构化的数据。

这些组件的结合使得Stable Audio 2.0能够生成长达三分钟、具有连贯音乐结构的高质量立体声音频。一项重要的新功能是**音频到音频的生成**，用户可以上传一个音频样本，并使用自然语言提示来转换它——例如，改变其乐器编配或风格。

### 6.3 第三维度：将扩散与3D高斯泼溅技术相结合

3D生成建模受到两个主要挑战的阻碍：与丰富的2D图像相比，大规模、高质量3D数据集的相对稀缺性，以及将标准扩散框架应用于像网格或点云这样离散且非结构化的3D表示的困难。

一个早期且流行的规避数据稀缺问题的方法是**从2D提升到3D**。像**DreamFusion**这样的方法引入了**分数蒸馏采样（Score Distillation Sampling, SDS）**，它使用一个强大的、预训练的2D文生图扩散模型作为先验。这个2D模型不进行微调；相反，它的分数函数被用来提供梯度，以从头开始优化一个3D表示（如神经辐射场，NeRF），使其与给定的文本提示相匹配。虽然这种方法很有创新性，但由于2D模型缺乏3D感知，它常常会产生像“双面雅努斯问题”（Janus problem，生成具有多个正面的物体）这样的瑕疵。

最近的工作则专注于直接在3D表示上执行扩散，其中**3D高斯泼溅（3D Gaussian Splatting, 3DGS）** 因其リアルタイム渲染速度和高保真度而成为一个特别有前途的候选者。然而，用扩散生成3DGS并非易事，因为一个3DGS场景是一组非结构化的、离散的高斯基元集合。

2024年和2025年的最新研究为这一表示挑战提出了几种解决方案：

* **DiffGS (NeurIPS 2024)**：这项工作避免了直接对离散高斯进行扩散。相反，它建议用三个连续的“高斯泼溅函数”来表示整个3DGS场景，这三个函数定义了空间中任意一点的高斯的概率、颜色和几何变换（位置、旋转、缩放）。然后，一个潜在扩散模型在这些连续函数的潜在编码上进行训练，从而使问题对于标准扩散框架来说变得易于处理。
* **L3DG (2024)**：该方法也使用潜在扩散方法。它首先训练一个矢量量化变分自编码器（VQ-VAE）来学习3D高斯场景的一个压缩的、离散的潜在空间。然后，一个扩散模型被训练来在这个潜在空间中生成新的编码，这些编码可以被解码成完整的3DGS场景。这种方法已显示出可扩展到整个房间大小的场景的能力。
* **GS-Diff (2025)**：该方法解决了从稀疏输入视图重建3DGS的问题。它使用一个预训练的多视图扩散模型来生成合理的“伪观测”——即场景的新相机视图。这些生成的视图提供了补充信息，有助于约束3DGS的优化，将一个不适定的、欠约束的问题转变为一个适定的问题。

### 6.4 生成式科学：蛋白质设计与材料发现

除了创意媒体，扩散模型正被应用于基础科学发现，探索分子和材料的广阔而复杂的构型空间，以设计具有期望功能特性的新颖结构。

#### 蛋白质设计

从头设计蛋白质的目标是生成新的氨基酸序列，这些序列能折叠成具有特定功能的稳定3D结构。这是一项具有挑战性的任务，需要遵守复杂的物理和化学约束，包括**SE(3)等变性**（蛋白质的性质应与其在3D空间中的全局旋转和平移无关）。

* **基于结构的生成（FrameDiff）**：像FrameDiff这样的模型直接在3D结构空间中操作。FrameDiff在SE(3)框架序列（每个氨基酸残基骨架的位置和方向）上执行扩散。它使用一个受AlphaFold2启发的、专门设计的SE(3)等变分数网络来学习反向过程。这使得它能够生成新颖且可设计的蛋白质骨架，而无需像许多其他方法那样依赖于预训练的结构预测网络。
* **可控的基于序列的生成（TaxDiff, 2024）**：相比之下，像TaxDiff这样的模型在序列空间中操作，但引入了一个关键的可控性元素。TaxDiff是一个基于Transformer的扩散模型，它以**分类学信息**（例如，“细菌”、“真核生物”）为条件。通过提供这个生物学类别作为控制信号，模型可以被引导生成不仅结构上合理，而且很可能属于特定生物家族的蛋白质序列，从而具有期望的特性。

#### 材料发现 (2024-2025)

材料科学中的一个核心问题是逆向设计具有特定性质（例如，用于电池或催化剂）的新型晶体材料。生成模型已显示出前景，但历史上在生成化学上稳定的结构方面成功率较低。

2024年的最新突破正在改变这一格局。**MatterGen**，一个用于材料发现的扩散模型，可以直接根据用户描述期望性质（例如，化学成分、电子性质、磁性性质）的提示，生成新颖、稳定的晶体结构。它显著优于以前的生成模型，经由昂贵的密度泛函理论（DFT）计算验证，其生成稳定、独特且新颖（SUN）材料的速率增加了一倍以上。该领域的更广泛趋势是**物理信息生成式AI**，其中像晶体学对称性这样的基本物理原理被直接嵌入到模型的学习过程中。这引导AI生成科学上有意义且物理上现实的材料，从简单的模式匹配转向一种引导式的、自主的发现形式。

## 第七部分：前沿与未来方向

随着扩散模型的成熟，研究前沿正在超越核心生成能力，进入更细致、更具挑战性的领域。2024年和2025年的最新工作聚焦于使这些模型更好地与人类价值观对齐，将其应用扩展到新的数据类型，并为其部署构建一个稳健的生态系统。最后一部分将概述这些前沿趋势，并勾勒出可能定义下一波创新浪潮的开放性问题。

### 7.1 与人类意图对齐：RLHF、DPO与安全 (2024-2025)

在广泛的互联网数据上训练的大规模扩散模型面临一个重大挑战：它们的目标——通常是最大化数据似然——并不能保证其输出在美学上令人愉悦、有帮助或安全。微调这些模型以更好地与人类偏好和价值观对齐的过程，是一个关键且活跃的研究领域，它大量借鉴了在LLM中开创的技术。

* **从人类反馈中进行强化学习（RLHF）**：传统方法包括在一个人类偏好数据集上训练一个独立的奖励模型（例如，给定由同一提示生成的两张图片，人类指出他们更喜欢哪一张）。这个奖励模型学习预测一个反映人类判断的分数。然后，使用强化学习（RL）来微调扩散模型，利用奖励模型的分数作为奖励信号，引导策略生成更受偏好的输出。使用AI标记的偏好进行的类似过程被称为RLAIF。
* **扩散直接偏好优化（DPO）**：一种更新、更直接的方法，DPO，绕过了训练独立奖励模型的需求。DPO将RL目标重新表述为一个简单的、类似分类的损失，可以直接在偏好数据上进行优化。它的工作原理是增加偏好响应相对于拒绝响应的相对可能性。**Diffusion-DPO**，于2023年末引入，成功地将此技术应用于扩散模型。使用像Pick-a-Pic这样的大规模偏好数据集，Diffusion-DPO已被用于微调像Stable Diffusion XL这样的模型，在视觉吸引力和提示对齐方面取得了显著改善。
* **安全与鲁棒性**：对齐不仅仅关乎美学；它对安全至关重要。这包括防止模型生成有害、有偏见或露骨的内容。一个持续存在的主要挑战是使这些安全对齐能够抵御**对抗性攻击**，即用户精心制作特定提示以绕过安全过滤器。未来的工作将聚焦于开发更鲁棒的对齐技术、持续的在线对齐以适应新威胁，以及能够同时平衡安全性、有益性和质量的多目标对齐方法。

### 7.2 离散与序列数据生成的新范式 (2024-2025)

尽管扩散模型在像图像这样的连续领域表现出色，但它们在像文本这样的离散数据上的应用面临挑战，包括固定长度的生成和与自回归模型相比效率低下的推理。最近的突破正开始弥合这一差距。

* **用于语言的块扩散（Block Diffusion）**：在ICLR 2025上展示的**Block Diffusion**模型，在自回归模型和扩散模型之间提供了一种优雅的插值。它在**令牌块（blocks of tokens）**上自回归地操作。在每个块内，令牌使用离散扩散过程并行生成。这种混合方法兼具两者的优点：它允许像扩散模型一样在块内进行高效的并行采样，同时又保持了像自回归模型一样处理可变长度序列和使用KV缓存来提高效率的能力。通过开发数据驱动的、能在训练期间最小化梯度方差的噪声时间表，Block Diffusion在语言建模基准上为扩散模型设定了新的性能标杆。
* **文本到序列生成（Text-to-Series Generation）**：于2025年提出的**Text-to-Series (T2S)**框架，是第一个用于从自然语言描述生成时间序列数据的领域无关模型。这在从金融到医疗保健等领域都有应用。T2S使用一个**长度自适应VAE**将不同长度的时间序列编码到一个一致的潜在空间中。然后，一个使用流匹配目标训练的扩散Transformer，学习在文本条件下生成这些潜在嵌入。通过在多种长度的数据上进行训练，该模型可以在推理时生成任何期望长度的、语义上对齐的时间序列，其表现在众多领域都优于基于扩散和基于LLM的基线。

### 7.3 实用生态系统：关键库与社区指南

扩散模型的迅速采用和发展，得益于一个充满活力的、由库、工具和社区中心组成的开源生态系统。

#### 核心库：

* **🤗 Diffusers**：来自Hugging Face的Diffusers已成为使用扩散模型的首选库。它提供了一个高度模块化和用户友好的工具箱，包含数百个预训练模型、调度器和用于从文生图到音频生成等广泛任务的流水线。其设计允许轻松混合和匹配组件以构建自定义的扩散系统。
* **ComfyUI**：这是一个功能强大且流行的、基于节点的图形用户界面，用于创建和执行复杂的扩散模型工作流。其可视化的、流程图式的结构使得实验涉及多个模型、LoRAs和ControlNets的复杂流水线变得容易。由于其灵活性，它在新模型如Stable Diffusion 3和混元-DiT的发布中被迅速采用。

#### 社区中心与开源模型：

* **Hugging Face Hub**：它作为开源AI社区的中央存储库，托管了数以千计的预训练扩散模型、适配器和数据集。它是像Stability AI和腾讯等公司的主要模型的主要分发点。
* **Civitai**：这个平台已成为创意AI社区的中心，特别是对于Stable Diffusion的用户。它是一个巨大的存储库，用户可以在这里分享和下载自定义训练的模型（ checkpoints）、LoRAs和文本反演（textual inversions）。它完美地体现了现代生态系统的“乐高积木”模块化特性，允许用户下载一个基础模型，然后浏览数千个社区创建的插件以实现特定的艺术风格或生成特定的角色。
* **旗舰开源模型**：像**Stable Diffusion 3**和腾讯的**混元-DiT（Hunyuan-DiT）**这样强大的开源基础模型的持续发布，是社区创新的关键驱动力，为新工具和创意作品的构建提供了坚实的平台。

### 7.4 结论性综合与未来研究轨迹

本路线图追溯了扩散模型的非凡历程，从其在概率和基于分数框架中的理论诞生，到其当前作为生成式AI主导力量的地位。这是一段快速、复利式创新的叙事。在生成质量上的初步突破之后，紧接着是对效率的强烈追求，这一过程从算法技巧（DDIM）发展到有原则的数值求解器，并最终到模型层面的压缩（蒸馏和基于流的模型）。与此同时，从基于CNN的U-Net到可扩展Transformer的架构演进，促成了该领域的“LLM化”，催生了具有涌现能力的巨型模型。与之相辅相成的是一个由控制（ControlNet）和定制（LoRA）组成的模块化生态系统的崛起，这使得创意应用大众化。最后，该领域扩展了其画布，通过架构、表示和数据的协同设计，应对视频、音频、3D和科学领域的独特挑战。

尽管取得了如此令人难以置信的进展，许多激动人心的挑战和研究轨迹依然存在：

* **迈向通用智能**：像Sora这样的模型所涌现的“世界模拟”能力提出了一个深刻的问题：持续的扩展是否会带来能够跨多种模态进行推理并与世界互动的更通用的AI系统？构建一个统一处理文本、图像、视频和音频的单一模型是一个重大的长期目标。
* **效率与端侧部署**：对效率的追求远未结束。虽然单步生成现在已成为可能，但在资源受限的边缘设备上部署这些巨型模型仍然是一个重大障碍。未来的研究将重点关注先进的量化技术、软硬件协同设计、用于高效主干的神经架构搜索，以及更优化的采样技术。
* **组合性与可控性**：虽然ControlNet和LoRA提供了强大的控制，但生成具有多个、相互作用且精确遵循复杂组合指令的复杂场景仍然是一个开放性问题。开发具有真正组合理解能力的模型是一个关键的前沿。
* **更深的理论理解**：许多经验性成功背后的“为什么”仍然没有被完全理解。为了指导更有原则的模型开发，需要对这些模型的泛化特性、它们所学分布的性质、对齐的数学原理以及涌现行为的原因有更深的理论把握。
* **科学与工业领域的数据稀缺性**：将扩散模型应用于像医学、工程或生物学这样的专业领域，常常受到高质量、大规模数据集可用性的限制。开发用于少样本生成、迁移学习以及有效整合特定领域物理约束的技术，将是释放生成式AI在这些高影响力领域潜力的关键。